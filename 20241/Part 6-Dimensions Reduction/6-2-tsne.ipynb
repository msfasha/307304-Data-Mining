{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. **Introduction to t-SNE**\n",
    "\n",
    "**t-SNE (t-Distributed Stochastic Neighbor Embedding)** is a dimensionality reduction technique primarily used for visualizing high-dimensional data in two or three dimensions. Unlike PCA, which focuses on capturing variance, t-SNE is more focused on preserving local relationships in the data, making it particularly useful for clustering and exploratory data analysis.\n",
    "\n",
    "**Applications of t-SNE**:\n",
    "- Visualizing clusters in high-dimensional data (e.g., MNIST digits, gene expression data).\n",
    "- Reducing the complexity of data for interpretation.\n",
    "- Identifying patterns or outliers in datasets.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **How t-SNE Works**\n",
    "\n",
    "t-SNE reduces high-dimensional data by creating a two- or three-dimensional map, aiming to preserve the relative distances of points (their \"neighborhoods\") in the reduced space.\n",
    "\n",
    "**Key steps in t-SNE**:\n",
    "\n",
    "1. **Pairwise Similarities**: In high-dimensional space, t-SNE calculates pairwise similarities between data points based on Gaussian distributions. Each point's neighborhood is modeled as a probability distribution.\n",
    "2. **Low-Dimensional Mapping**: t-SNE tries to replicate the high-dimensional relationships in the low-dimensional space using t-distributions for pairwise similarities.\n",
    "3. **Cost Function Optimization**: t-SNE minimizes the Kullback-Leibler (KL) divergence between the two probability distributions (in high and low dimensions). The goal is to maintain the local structure of the data.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Mathematical Explanation**\n",
    "\n",
    "1. **High-Dimensional Similarities**:\n",
    "   For each pair of points $ x_i $ and $ x_j $, t-SNE computes the conditional probability $ p_{j|i} $, representing how similar point $ x_j $ is to point $ x_i $, based on a Gaussian distribution centered at $ x_i $:\n",
    "   \n",
    "   $$\n",
    "   p_{j|i} = \\frac{\\exp(- \\| x_i - x_j \\|^2 / 2\\sigma_i^2)}{\\sum_{k \\neq i} \\exp(- \\| x_i - x_k \\|^2 / 2\\sigma_i^2)}\n",
    "   $$\n",
    "\n",
    "2. **Low-Dimensional Similarities**:\n",
    "   Similarly, in the low-dimensional space (e.g., 2D), t-SNE computes the pairwise similarities $ q_{ij} $ between points $ y_i $ and $ y_j $, using a t-distribution with one degree of freedom (Student's t-distribution):\n",
    "   \n",
    "   $$\n",
    "   q_{ij} = \\frac{(1 + \\| y_i - y_j \\|^2)^{-1}}{\\sum_{k \\neq l} (1 + \\| y_k - y_l \\|^2)^{-1}}\n",
    "   $$\n",
    "\n",
    "3. **Cost Function (KL Divergence)**:\n",
    "   t-SNE aims to minimize the Kullback-Leibler divergence between the two distributions $ P $ and $ Q $:\n",
    "   \n",
    "   $$\n",
    "   KL(P \\| Q) = \\sum_{i \\neq j} p_{ij} \\log \\frac{p_{ij}}{q_{ij}}\n",
    "   $$\n",
    "\n",
    "The algorithm adjusts the positions of points in the low-dimensional space to minimize this divergence, ensuring that points that were close in the high-dimensional space remain close in the low-dimensional space.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Step-by-Step Example**\n",
    "\n",
    "Let’s consider a simple dataset with four-dimensional data that we want to visualize in 2D using t-SNE.\n",
    "\n",
    "| X1  | X2  | X3  | X4  |\n",
    "|-----|-----|-----|-----|\n",
    "| 1.0 | 2.0 | 3.0 | 4.0 |\n",
    "| 5.0 | 6.0 | 7.0 | 8.0 |\n",
    "| 1.5 | 1.8 | 2.5 | 3.5 |\n",
    "| 8.0 | 7.8 | 8.5 | 9.0 |\n",
    "| 1.1 | 2.1 | 3.1 | 4.1 |\n",
    "| 9.0 | 10.0| 11.0| 12.0|\n",
    "\n",
    "We will reduce this dataset from 4 dimensions to 2 dimensions using t-SNE to visualize it.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. **Python Code Example**\n",
    "\n",
    "Here’s how to implement t-SNE using Python’s `scikit-learn` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "perplexity must be less than n_samples",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Step 2: Apply t-SNE to reduce from 4 dimensions to 2 dimensions\u001b[39;00m\n\u001b[0;32m     16\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m df_tsne \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Step 3: Plot the 2D results\u001b[39;00m\n\u001b[0;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(df_tsne[:, \u001b[38;5;241m0\u001b[39m], df_tsne[:, \u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\me\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\me\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\me\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1175\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[1;32m-> 1175\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[1;32mc:\\Users\\me\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:864\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperplexity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 864\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperplexity must be less than n_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: perplexity must be less than n_samples"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Create the dataset\n",
    "data = {'X1': [1.0, 5.0, 1.5, 8.0, 1.1, 9.0],\n",
    "        'X2': [2.0, 6.0, 1.8, 7.8, 2.1, 10.0],\n",
    "        'X3': [3.0, 7.0, 2.5, 8.5, 3.1, 11.0],\n",
    "        'X4': [4.0, 8.0, 3.5, 9.0, 4.1, 12.0]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Apply t-SNE to reduce from 4 dimensions to 2 dimensions\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "df_tsne = tsne.fit_transform(df)\n",
    "\n",
    "# Step 3: Plot the 2D results\n",
    "plt.scatter(df_tsne[:, 0], df_tsne[:, 1])\n",
    "plt.title('t-SNE Projection to 2D')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Display the transformed data\n",
    "print(\"Original Data:\\n\", df)\n",
    "print(\"\\nTransformed Data (2 Dimensions):\\n\", df_tsne)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- **Step 1**: We create a 4-dimensional dataset.\n",
    "- **Step 2**: We apply t-SNE to reduce the dataset from 4 dimensions to 2 dimensions.\n",
    "- **Step 3**: We visualize the transformed data in a 2D scatter plot.\n",
    "- **Step 4**: We display the transformed data in the 2D space.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. **Choosing Parameters for t-SNE**\n",
    "\n",
    "t-SNE has a few important parameters that can affect the quality of the results:\n",
    "\n",
    "1. **Perplexity**: It is related to the number of nearest neighbors considered for each point. A common range is between 5 and 50. Smaller datasets benefit from lower perplexity values, while larger datasets may need higher values.\n",
    "   \n",
    "   Example:\n",
    "   ```python\n",
    "   tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "   ```\n",
    "\n",
    "2. **Learning Rate**: Controls how much the points are adjusted during optimization. If the learning rate is too high, points might collapse; if it's too low, optimization might be slow. Typical values range from 10 to 1000.\n",
    "\n",
    "   Example:\n",
    "   ```python\n",
    "   tsne = TSNE(n_components=2, learning_rate=200, random_state=42)\n",
    "   ```\n",
    "\n",
    "3. **Number of Iterations**: Determines how many times the algorithm iterates to optimize the cost function. More iterations can lead to better results but will also increase computation time.\n",
    "\n",
    "---\n",
    "\n",
    "#### 7. **Advantages and Disadvantages of t-SNE**\n",
    "\n",
    "**Advantages**:\n",
    "- **Non-linear**: Unlike PCA, t-SNE captures non-linear relationships and preserves the local structure of the data.\n",
    "- **Effective for Visualization**: t-SNE is particularly useful for visualizing complex, high-dimensional data in a 2D or 3D space.\n",
    "\n",
    "**Disadvantages**:\n",
    "- **Computationally Expensive**: t-SNE is slower than other dimensionality reduction techniques like PCA, especially for large datasets.\n",
    "- **Not a Clustering Algorithm**: t-SNE is often mistaken for a clustering algorithm, but it is a visualization tool. Clusters seen in t-SNE plots are not always reliable.\n",
    "- **Sensitive to Parameter Choices**: Results can vary significantly depending on the choice of parameters like perplexity and learning rate.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. **Conclusion**\n",
    "\n",
    "t-SNE is a powerful and widely used technique for visualizing high-dimensional data in a reduced space. While it is computationally intensive and sensitive to parameters, it excels at preserving the local structure of data, making it ideal for clustering and exploratory analysis.\n",
    "\n",
    "**Homework**:  \n",
    "Apply t-SNE to a high-dimensional dataset (e.g., the MNIST dataset), experiment with different perplexity values, and visualize the results in 2D. Compare the performance and results of t-SNE with PCA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
