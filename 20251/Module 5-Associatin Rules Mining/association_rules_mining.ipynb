{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Alt Text](https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/header.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: flex-start; align-items: center;\">\n",
    "    <a href=\"https://colab.research.google.com/github/msfasha/307304-Data-Mining/blob/main/20251/Module%205-Associatin%20Rules%20Mining/association_rules_mining.ipynb\" target=\"_blank\">\n",
    "        <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" style=\"height: 25px; margin-right: 20px;\">\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    ".box-title {\n",
    "    background-color: #8F0177;\n",
    "    padding: 15px;\n",
    "    border-radius: 8px;\n",
    "    color: white;\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div class=\"box-title\">\n",
    "    <h3 style=\"margin:0;\">Introduction to Association Rule Mining – Market Basket Analysis (MBA)</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association rule mining is a data mining technique used to uncover **if–then relationships** between items in large datasets, such as retail transaction logs. These relationships, known as **association rules**, capture patterns of items that frequently occur together (called **co-occurrences**).\n",
    "\n",
    "In the context of **market basket analysis**, association rules help answer questions like: *“Which products are often bought together?”* For example, suppose we find that 75% of customers who buy cereal also buy milk. We can express this as the rule:\n",
    "\n",
    "$\\{\\mathrm{cereal}\\} \\Rightarrow \\{\\mathrm{milk}\\}$\n",
    "\n",
    "This rule suggests that customers who purchase cereal often purchase milk as well. Such insights can guide **marketing and retail decisions**, including promotional strategies, product bundling, and shelf placement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/mba.png\" alt=\"Association Ruels Mining\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/mall_bill.png\" alt=\"Mall Bill\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: flex-start; align-items: center;\">\n",
    "    <a href=\"https://www.youtube.com/watch?v=guVvtZ7ZClw\" target=\"_blank\">\n",
    "        <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/youtube.png\" alt=\"KMeans Youtube Video\" style=\"height: 40px;\">\n",
    "    <a href=\"https://uopstdedu-my.sharepoint.com/:f:/g/personal/mohammed_fasha_uop_edu_jo/EkNUft0LJ_JJg5SdPETsj90BXHoevd0DlMBwDY6Or8YfCw?e=L73iKu\" target=\"_blank\">\n",
    "        <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/video_icon.png\" alt=\"Recorded Video Lecture\" style=\"height: 100px;margin-left:20px;\"\">\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#8F0177;\n",
    "    padding:15px;\n",
    "    border-radius:8px;\n",
    "    color:white;\n",
    "    display:flex;\n",
    "    align-items:center;\n",
    "\">\n",
    "    <h3 style=\"margin:0;\">Association Rule Use Cases and Domains</h3>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| #  | Domain                     | Use Case                  | Description (what + why it’s useful)                                                    | Example Association / Pattern                                   |\n",
    "|----|----------------------------|---------------------------|-----------------------------------------------------------------------------------------|------------------------------------------------------------------|\n",
    "| 1  | Healthcare                 | Disease diagnosis         | Identifying associations between symptoms and diseases to support faster, more accurate diagnosis | {fever, cough} → {flu}                                          |\n",
    "| 2  | Healthcare                 | Drug interactions         | Discovering meds often prescribed together or risky combos to improve treatment safety  | {drug A, drug B} → {adverse reaction}                           |\n",
    "| 3  | Web Usage Mining           | Website optimization      | Analyzing navigation paths to remove friction and increase conversions                  | {homepage, product page} → {checkout}                           |\n",
    "| 4  | Web Usage Mining           | Recommendation systems    | Finding frequently co-accessed content to power “you may also like” recommendations     | {clicked “smartphone”} → {clicked “smartphone accessories”}     |\n",
    "| 5  | Education                  | Student behavior analysis | Finding patterns in course enrollment to improve course offerings and planning          | {math101, cs101} → {stat101}                                    |\n",
    "| 6  | Education                  | Learning paths            | Identifying typical learning sequences to design better curricula and study plans       | {topic A, topic B} → {topic C}                                  |\n",
    "| 7  | Telecommunications         | Customer churn analysis   | Detecting usage patterns linked to cancellations to target retention campaigns          | {low data usage, few calls} → {churn}                           |\n",
    "| 8  | Telecommunications         | Service bundling          | Finding services often bought together to create attractive bundles and offers          | {broadband, mobile} → {TV subscription}                         |\n",
    "| 9  | Banking & Finance          | Fraud detection           | Uncovering transaction patterns linked to fraud to trigger alerts and investigations    | {high transaction frequency, odd hours} → {fraud}               |\n",
    "| 10 | Banking & Finance          | Loan approvals            | Identifying traits of successful loans to refine credit policies and scoring models     | {high income, good credit score} → {loan approved}              |\n",
    "| 11 | Manufacturing              | Fault detection           | Linking machine conditions to failures for early warning and preventive maintenance     | {high temperature, low pressure} → {equipment failure}          |\n",
    "| 12 | Manufacturing              | Supply chain optimization | Discovering material usage patterns to optimize inventory and production planning       | {material A, material B} → {product C}                          |\n",
    "| 13 | Retail (beyond basket)     | Shelf placement           | Grouping products often bought together to improve store layout and increase sales      | {item A, item B} → {co-located on shelf}                        |\n",
    "| 14 | Retail (beyond basket)     | Customer segmentation     | Finding purchase behavior patterns to tailor promotions to specific customer segments   | {frequent discount purchases} → {low brand loyalty}             |\n",
    "| 15 | Social Media Analysis      | Trending topics           | Finding hashtag co-occurrences to understand themes and plan relevant content           | {#climatechange, #sustainability} → {#renewableenergy}          |\n",
    "| 16 | Social Media Analysis      | User behavior patterns    | Analyzing engagement sequences to optimize content for likes, comments, and shares      | {likes post, comments on post} → {shares post}                  |\n",
    "| 17 | Energy Sector              | Usage patterns            | Linking context (time, devices) to consumption peaks to improve demand forecasting      | {high A/C usage, weekend} → {peak energy consumption}           |\n",
    "| 18 | Energy Sector              | Smart grid analysis       | Detecting conditions before failures to improve grid reliability and maintenance        | {low voltage, high demand} → {power outage}                     |\n",
    "| 19 | Transportation & Logistics | Traffic analysis          | Discovering conditions that cause congestion to improve planning and routing            | {morning rush hour, bad weather} → {traffic jam}                |\n",
    "| 20 | Transportation & Logistics | Route optimization        | Finding route combinations tied to faster delivery to optimize logistics operations     | {route A, route B} → {delivered faster}                         |\n",
    "| 21 | E-commerce                 | User preferences          | Identifying viewing/buying patterns to personalize recommendations and UX               | {view item A} → {view similar item B}                           |\n",
    "| 22 | E-commerce                 | Cross-selling             | Finding items frequently bought together to suggest add-ons and increase basket value   | {bought laptop} → {bought laptop bag}                           |\n",
    "| 23 | Sports Analytics           | Performance metrics       | Linking player actions to outcomes to guide tactics and training                        | {high possession, accurate passes} → {win}                      |\n",
    "| 24 | Sports Analytics           | Injury prevention         | Identifying conditions before injuries to adjust training load and reduce risk          | {high training load, lack of rest} → {injury risk}              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#8F0177;\n",
    "    padding:15px;\n",
    "    border-radius:8px;\n",
    "    color:white;\n",
    "    display:flex;\n",
    "    align-items:center;\n",
    "\">\n",
    "    <h3 style=\"margin:0;\">Approaches to Association Rule Mining\n",
    "</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To discover meaningful patterns such as items frequently bought together, we need methods that can search through large transactional datasets efficiently. A straightforward exhaustive search is theoretically possible but becomes computationally explosive as the number of items grows. Practical association rule mining therefore relies on specialized algorithms designed to avoid this combinatorial blow-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Brute force:**\n",
    "\n",
    "  * Enumerate all itemsets and all possible rules\n",
    "  * Compute support and confidence for each\n",
    "  * Grows exponentially; infeasible for real datasets\n",
    "\n",
    "* **Efficient algorithms:**\n",
    "\n",
    "  * **Apriori** – level-wise search with pruning\n",
    "  * **FP-Growth** – compresses data into FP-tree, avoids candidate generation\n",
    "  * **Eclat** – uses vertical data format and intersections\n",
    "  * All reduce the search space dramatically compared to brute force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#8F0177;\n",
    "    padding:15px;\n",
    "    border-radius:8px;\n",
    "    color:white;\n",
    "    display:flex;\n",
    "    align-items:center;\n",
    "\">\n",
    "    <h3 style=\"margin:0;\">The Apriori Algorithm</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori is a classic algorithm for **finding frequent itemsets** and **deriving association rules** in transactional databases (e.g., shopping baskets, web logs). It is based on the idea that **every subset of a frequent itemset must also be frequent**.\n",
    "\n",
    "**Key points:**\n",
    "\n",
    "* Proposed by **Agrawal & Srikant (1994)**.\n",
    "* Works on **transaction data** (e.g., sets of items bought together).\n",
    "* First finds **frequent single items**, then **grows** them into larger itemsets as long as they remain frequent.\n",
    "* Uses a **bottom-up, level-wise** search with **candidate generation** and testing.\n",
    "* Stops when **no more frequent extensions** can be found.\n",
    "* The resulting frequent itemsets are used to build **association rules** (e.g., for **market basket analysis**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/apriori-algorithm.jpg\" alt=\"Apriori Algorithm\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This diagram shows the candidate itemset generation structure used by the Apriori algorithm.  \n",
    "- Each level represents itemsets of increasing size, starting from single items at the top and building toward larger combinations below.  \n",
    "- Apriori works by repeatedly joining frequent itemsets to form larger candidates, while pruning any itemset whose subsets were not frequent in earlier steps.  \n",
    "- In the diagram, every node represents a candidate itemset, and the lines show how each larger set is generated from smaller ones by adding one item at a time.  \n",
    "- Only itemsets whose all subsets appear in the previous level are kept, which reduces the search space.  \n",
    "- In essence, the figure visualizes the core Apriori idea: grow itemsets level by level, but prune aggressively using the principle that all subsets of a frequent itemset must themselves be frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#8F0177;\n",
    "    padding:15px;\n",
    "    border-radius:8px;\n",
    "    color:white;\n",
    "    display:flex;\n",
    "    align-items:center;\n",
    "\">\n",
    "    <h3 style=\"margin:0;\">Creating Association Rules using The Apriori Algorithm</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create association rules, we use 3 metrics:\n",
    "1. Support: finds the popular items and builds initial rules.\n",
    "2. Confidence: Enhance initial rules by finding true relationships.\n",
    "3. Lift: Enhance rules by acomodating for popular items effect (x -> y where x is popular e.g. bread in a bakery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/3_mba_metrics.png\" alt=\"The 3 Metrics of MBA Bill\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#8F0177;\n",
    "    padding:15px;\n",
    "    border-radius:8px;\n",
    "    color:white;\n",
    "    display:flex;\n",
    "    align-items:center;\n",
    "\">\n",
    "    <h3 style=\"margin:0;\">1. Support Measure</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support measures **how often** an itemset appears in the dataset.  \n",
    "It is a probability-like measure between 0 and 1.\n",
    "\n",
    "**Definition**\n",
    "\n",
    "$ \\text{Support(X)} = \\frac{\\text{Number of transactions containing X}}{\\text{Total transactions}} $\n",
    "\n",
    "**Range**\n",
    "\n",
    "- 0 ≤ Support(X) ≤ 1  \n",
    "  - 0 → X never appears  \n",
    "  - 1 → X appears in every transaction  \n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "- **High support** → X is common, good candidate for rules  \n",
    "- **Low support** → X is rare, often less useful (unless domain-specific)\n",
    "\n",
    "**Thresholds in practice**\n",
    "\n",
    "- Set a **minimum support** to filter out infrequent itemsets.  \n",
    "- Typical starting points:  \n",
    "  - **5–10%** for large retail datasets  \n",
    "  - **20–30%** for smaller datasets or only very popular combinations  \n",
    "- Too high → you miss interesting but less frequent patterns  \n",
    "- Too low → you keep many unimportant, noisy patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Let’s assume that we have a small dataset with 12 transactions:\n",
    "\n",
    "| **Transaction ID** | **Item 1** | **Item 2** | **Item 3** | **Item 4** | **Item 5** |\n",
    "|---------------------|------------|------------|------------|------------|------------|\n",
    "| 1                   | Milk       | Egg        | Bread      | Butter     |            |\n",
    "| 2                   | Milk       | Butter     | Egg        | Ketchup    |            |\n",
    "| 3                   | Bread      | Butter     | Ketchup    |            |            |\n",
    "| 4                   | Milk       | Bread      | Butter     |            |            |\n",
    "| 5                   | Bread      | Butter     | Cookies    |            |            |\n",
    "| 6                   | Milk       | Bread      | Butter     | Cookies    |            |\n",
    "| 7                   | Milk       | Cookies    |            |            |            |\n",
    "| 8                   | Milk       | Bread      | Butter     |            |            |\n",
    "| 9                   | Bread      | Butter     | Egg        | Cookies    |            |\n",
    "| 10                  | Milk       | Butter     | Bread      |            |            |\n",
    "| 11                  | Milk       | Bread      | Butter     |            |            |\n",
    "| 12                  | Milk       | Bread      | Cookies    | Ketchup    |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First, we set out the **Minimum Support** value to:\n",
    " - 50% (focus on items present in at least half of the transactions), this value can be set to 5% or 10% in real-life situations with large datasets.\n",
    "\n",
    " **Step 1: Dataset Transformation**\n",
    "Convert the dataset into a binary format:\n",
    "\n",
    "| Transaction | Milk | Egg | Bread | Butter | Ketchup | Cookies |\n",
    "|-------------|------|-----|-------|--------|---------|---------|\n",
    "| 1           | 1    | 1   | 1     | 1      | 0       | 0       |\n",
    "| 2           | 1    | 1   | 0     | 1      | 1       | 0       |\n",
    "| 3           | 0    | 0   | 1     | 1      | 1       | 0       |\n",
    "| 4           | 1    | 0   | 1     | 1      | 0       | 0       |\n",
    "| 5           | 0    | 0   | 1     | 1      | 0       | 1       |\n",
    "| 6           | 1    | 0   | 1     | 1      | 0       | 1       |\n",
    "| 7           | 1    | 0   | 0     | 0      | 0       | 1       |\n",
    "| 8           | 1    | 0   | 1     | 1      | 0       | 0       |\n",
    "| 9           | 0    | 1   | 1     | 1      | 0       | 1       |\n",
    "| 10          | 1    | 0   | 1     | 1      | 0       | 0       |\n",
    "| 11          | 1    | 0   | 1     | 1      | 0       | 0       |\n",
    "| 12          | 1    | 0   | 1     | 0      | 1       | 1       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Identify Frequent 1-Itemsets**  \n",
    "The algorithm starts by calculating the support for each single item.\n",
    "\n",
    "| Item     | Support Count | Support (%) | Frequent? |\n",
    "|----------|---------------|-------------|-----------|\n",
    "| Milk     | 9             | 75%         | Yes       |\n",
    "| Egg      | 3             | 25%         | No        |\n",
    "| Bread    | 10            | 83%         | Yes       |\n",
    "| Butter   | 10            | 83%         | Yes       |\n",
    "| Ketchup  | 3             | 25%         | No        |\n",
    "| Cookies  | 5             | 42%         | No        |\n",
    "\n",
    "**Frequent 1-itemsets**: `{Milk}`, `{Bread}`, `{Butter}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Generate 2-Itemsets**  \n",
    "Now, combine frequent 1-itemsets into 2-itemsets and calculate their support.\n",
    "\n",
    "| Itemset           | Support Count | Support (%) | Frequent? |\n",
    "|--------------------|---------------|-------------|-----------|\n",
    "| {Milk, Bread}     | 7             | 58%         | Yes       |\n",
    "| {Milk, Butter}    | 7             | 58%         | Yes       |\n",
    "| {Bread, Butter}   | 9             | 75%         | Yes       |\n",
    "\n",
    "**Frequent 2-itemsets**: `{Milk, Bread}`, `{Milk, Butter}`, `{Bread, Butter}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Generate 3-Itemsets**  \n",
    "Combine frequent 2-itemsets into 3-itemsets and calculate their support.\n",
    "\n",
    "| Itemset                   | Support Count | Support (%) | Frequent? |\n",
    "|----------------------------|---------------|-------------|-----------|\n",
    "| {Milk, Bread, Butter}     | 6             | 50%         | Yes       |\n",
    "\n",
    "**Frequent 3-itemset**: `{Milk, Bread, Butter}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: No Larger Itemsets Can Be Created**  \n",
    "Since there are no frequent 4-itemsets (support would drop below 50%), we stop here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Step 6: Generate Initial Association Rules**\n",
    "\n",
    "Now, use the frequent itemsets to generate association rules, we will focus on the largest item set, we can create rules from smaller ones if needed.\n",
    "\n",
    "Rules from `{Milk, Bread, Butter}`:\n",
    "1. **Rule 1**: $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$  \n",
    "\n",
    "$$Support =  P(\\text{Milk, Bread, Butter}) = 6/12 = 50\\% $$\n",
    "\n",
    "1. **Rule 2**: $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$  \n",
    "\n",
    "$$ Support = P(\\text{Milk, Bread, Butter}) = 6/12 = 50\\% $$\n",
    "\n",
    "2. **Rule 3**: $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$  \n",
    "\n",
    "$$ Support = P(\\text{Milk, Bread, Butter}) = 6/12 = 50\\% $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#8F0177;\n",
    "    padding:15px;\n",
    "    border-radius:8px;\n",
    "    color:white;\n",
    "    display:flex;\n",
    "    align-items:center;\n",
    "\">\n",
    "    <h3 style=\"margin:0;\">Why Support Is Not Enough (SmartBuy Example)</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support is **symmetric**, it does not give us the direction of the relation, it tells us **how often they appear together**, but not **which direction** is more useful.\n",
    "\n",
    "For example, assume SmartBuy has **1,000 transactions** in a certain period, and we observe:\n",
    "\n",
    "* 200 transactions include a **Phone**\n",
    "* 800 transactions include a **Cover**\n",
    "* 120 transactions include **both** a Phone and a Cover\n",
    "\n",
    "So the **support** of the pair is:\n",
    "\n",
    "$\n",
    "\\text{support}(\\text{Phone} \\cap \\text{Cover})\n",
    "= \\frac{120}{1000}\n",
    "= 12%.\n",
    "$\n",
    "\n",
    "This 12% is the same for both:\n",
    "\n",
    "* Phone → Cover\n",
    "* Cover → Phone\n",
    "\n",
    "Support alone just says: *“Phones and covers occur together in 12% of all SmartBuy transactions.”*\n",
    "It does **not** tell us which rule is actually useful.\n",
    "\n",
    "### Direction 1: Phone → Cover (Makes Sense)\n",
    "\n",
    "$\n",
    "\\text{confidence}(\\text{Phone} \\rightarrow \\text{Cover})\n",
    "= \\frac{\\text{support}(\\text{Phone} \\cap \\text{Cover})}\n",
    "{\\text{support}(\\text{Phone})}\n",
    "= \\frac{120/1000}{200/1000}\n",
    "= \\frac{120}{200}\n",
    "= 60%.\n",
    "$\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "> In **60%** of transactions where a customer buys a **phone**, they also buy a **cover**.\n",
    "\n",
    "This is a **strong rule** and very reasonable:\n",
    "If someone is buying a phone, suggesting a cover is a good cross-sell.\n",
    "\n",
    "### Direction 2: Cover → Phone (Much Weaker)\n",
    "\n",
    "$\n",
    "\\text{confidence}(\\text{Cover} \\rightarrow \\text{Phone})\n",
    "= \\frac{\\text{support}(\\text{Phone} \\cap \\text{Cover})}\n",
    "{\\text{support}(\\text{Cover})}\n",
    "= \\frac{120/1000}{800/1000}\n",
    "= \\frac{120}{800}\n",
    "= 15%.\n",
    "$\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "> In only **15%** of transactions where a customer buys a **cover**, they also buy a **phone**.\n",
    "\n",
    "This is **quite low**. Most people buying covers already **have** a phone, so suggesting a new phone when they buy a cover is usually **not useful**.\n",
    "\n",
    "### Takeaway\n",
    "\n",
    "* Same support for the pair:\n",
    "  $\n",
    "  \\text{support}(\\text{Phone} \\cap \\text{Cover}) = 12%.\n",
    "  $\n",
    "* Very different confidences:\n",
    "\n",
    "  * Phone → Cover: **60%** (strong, useful rule)\n",
    "  * Cover → Phone: **15%** (weak, not very useful)\n",
    "\n",
    "So even though **support is the same**, only\n",
    "\n",
    "$\n",
    "\\text{Phone} \\rightarrow \\text{Cover}\n",
    "$\n",
    "\n",
    "really makes sense as a business rule; the reverse direction does not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#8F0177;\n",
    "    padding:15px;\n",
    "    border-radius:8px;\n",
    "    color:white;\n",
    "    display:flex;\n",
    "    align-items:center;\n",
    "\">\n",
    "    <h3 style=\"margin:0;\">2. Confidence Measure</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose the more useful rule, we use **confidence**.\n",
    "\n",
    "**Definition**\n",
    "\n",
    "Confidence measures how often \\(Y\\) appears when \\(X\\) appears (how reliable the rule is):\n",
    "\n",
    "$\n",
    "\\text{conf}(X \\rightarrow Y) =\n",
    "\\frac{\\text{support}(X \\cap Y)}{\\text{support}(X)}.\n",
    "$\n",
    "\n",
    "- **Range:** \\(0 $\\le \\text{conf}(X \\rightarrow Y) \\le$ 1\\)\n",
    "  - 0 → the rule never holds  \n",
    "  - 1 → the rule always holds  \n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "- **High confidence (~1):** when \\(X\\) happens, \\(Y\\) almost always happens (strong rule).  \n",
    "- **Low confidence (~0):** when \\(X\\) happens, \\(Y\\) rarely happens (weak rule).  \n",
    "\n",
    "In practice, we often set a **minimum confidence threshold** (e.g., 70–80%) and keep only rules above that value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..........................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Step 7: Validate the Rules using Confidence**\n",
    "\n",
    "First, let us set the **Minimum Confidence** value to: 70%.\n",
    "\n",
    "Rules from `{Milk, Bread, Butter}`:\n",
    "1. **Rule 1**: $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$  \n",
    "   \n",
    "$$Confidence = P(\\text{Butter}|\\text{Milk, Bread}) = \\frac{P(\\text{Milk, Bread, Butter})}{P(\\text{Milk, Bread})} = \\frac{6}{7} = 85\\%\n",
    "     $$\n",
    "\n",
    "1. **Rule 2**: $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$  \n",
    "   \n",
    "$$Confidence = P(\\text{Bread}|\\text{Milk, Butter}) = \\frac{P(\\text{Milk, Bread, Butter})}{P(\\text{Milk, Butter})} = \\frac{6}{7} = 85\\%\n",
    "     $$\n",
    "\n",
    "1. **Rule 3**: $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$  \n",
    "   \n",
    "$$Confidence = P(\\text{Milk}|\\text{Bread, Butter}) = \\frac{P(\\text{Milk, Bread, Butter})}{P(\\text{Bread, Butter})} = \\frac{6}{9} \\approx 66\\%\n",
    "     $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#8F0177;\n",
    "    padding:15px;\n",
    "    border-radius:8px;\n",
    "    color:white;\n",
    "    display:flex;\n",
    "    align-items:center;\n",
    "\">\n",
    "    <h3 style=\"margin:0;\">3. Lift Measure</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence alone can be **misleading** when the consequent \\(Y\\) is very frequent: a rule \\(X $\\rightarrow$ Y\\) may have high confidence just because \\(Y\\) is common.\n",
    "\n",
    "**Example (bakery)**  \n",
    "- P(bread) = 0.80  \n",
    "- P(cake) = 0.20  \n",
    "- P(cake ∩ bread) = 0.16  \n",
    "\n",
    "Then:\n",
    "\n",
    "$\n",
    "\\text{conf}(\\text{cake} \\rightarrow \\text{bread})\n",
    "= \\frac{0.16}{0.20} = 0.8\n",
    "$\n",
    "\n",
    "Confidence is 80%, but bread is already in 80% of all orders, so cake buyers are **not** more likely than average to buy bread.\n",
    "\n",
    "To correct for this, we use **lift**:\n",
    "\n",
    "$\n",
    "\\text{Lift}(X \\rightarrow Y)\n",
    "= \\frac{\\text{Confidence}(X \\rightarrow Y)}{\\text{Support}(Y)}\n",
    "= \\frac{P(Y \\mid X)}{P(Y)}\n",
    "$\n",
    "\n",
    "In the example:\n",
    "\n",
    "$\n",
    "\\text{lift}(\\text{cake} \\rightarrow \\text{bread})\n",
    "= \\frac{0.8}{0.8} = 1\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".............................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpreting Lift**\n",
    "\n",
    "Lift measures how strongly two items or itemsets are associated:\n",
    "\n",
    "* $(\\text{lift} > 1)$: items occur together **more often than expected** (positive association).\n",
    "* $(\\text{lift} = 1)$: items occur together **as often as expected** under independence (no association).\n",
    "* $(\\text{lift} < 1)$: items occur together **less often than expected** (negative association).\n",
    "\n",
    "So lift tells us whether items co-occur more (or less) frequently than expected under independence, making it a useful complement to confidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "................................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Step 8: Validate Rules using the Lift**\n",
    "\n",
    "First, we set the **Lift > 1** for actionable rules\n",
    "\n",
    "1. **Rule 1**: $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$  \n",
    "   \n",
    "     $$\n",
    "     \\text{Lift} = \\frac{P(\\text{Butter}|\\text{Milk, Bread})}{P(\\text{Butter})} = \\frac{0.85}{0.83} \\approx 1.02\n",
    "     $$\n",
    "\n",
    "2. **Rule 2**: $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$  \n",
    "\n",
    "     $$\n",
    "     \\text{Lift} = \\frac{P(\\text{Bread}|\\text{Milk, Butter})}{P(\\text{Bread})} = \\frac{0.85}{0.83} \\approx 1.02\n",
    "     $$\n",
    "\n",
    "3. **Rule 3**: $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$  \n",
    "   \n",
    "     $$\n",
    "     \\text{Lift} = \\frac{P(\\text{Milk}|\\text{Bread, Butter})}{P(\\text{Milk})} = \\frac{0.66}{0.75} \\approx .88\n",
    "     $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#8F0177;\n",
    "    padding:15px;\n",
    "    border-radius:8px;\n",
    "    color:white;\n",
    "    display:flex;\n",
    "    align-items:center;\n",
    "\">\n",
    "    <h3 style=\"margin:0;\">Final Results</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequent Itemsets:\n",
    "- **1-itemsets**: `{Milk}`, `{Bread}`, `{Butter}`\n",
    "- **2-itemsets**: `{Milk, Bread}`, `{Milk, Butter}`, `{Bread, Butter}`\n",
    "- **3-itemset**: `{Milk, Bread, Butter}`\n",
    "\n",
    "Rules:\n",
    "| Rule                           | Support | Confidence | Lift  | Actionable? |\n",
    "|--------------------------------|---------|------------|-------|-------------|\n",
    "| $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$ | 50%     | 85%      | 1.02  | Yes         |\n",
    "| $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$ | 50%     | 85%      | 1.02  | Yes         |\n",
    "| $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$ | 50%     | 66%      | .88  | No         |\n",
    "\n",
    "**Interpretation and Actionable Insights**\n",
    "| Rule                           | Explaniation |\n",
    "|--------------------------------|--------------|\n",
    "| $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$ |Customers buying Milk and Bread are highly likely (85%) to also buy Butter. Consider bundling these items.         |\n",
    "| $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$ | Strong association; placing these items together could increase sales.         |\n",
    "| $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$ | Suggests that Milk is a complementary product to Bread and Butter, Weak lift thought         |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#8F0177;\n",
    "    padding:15px;\n",
    "    border-radius:8px;\n",
    "    color:white;\n",
    "    display:flex;\n",
    "    align-items:center;\n",
    "\">\n",
    "    <h3 style=\"margin:0;\">Python Example</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement the **Apriori algorithm** using the **`mlxtend`** library for frequent itemset mining and rule generation.\n",
    "\n",
    "**a. Install Required Libraries**\n",
    "Make sure you have the required libraries installed:\n",
    "```bash\n",
    "pip install pandas mlxtend\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Load the Dataset**\n",
    "We will represent the dataset as a **binary transaction matrix** where each row is a transaction, and each column is an item (1 = purchased, 0 = not purchased)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Milk</th>\n",
       "      <th>Egg</th>\n",
       "      <th>Bread</th>\n",
       "      <th>Butter</th>\n",
       "      <th>Ketchup</th>\n",
       "      <th>Cookies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Milk  Egg  Bread  Butter  Ketchup  Cookies\n",
       "0      1    1      1       1        0        0\n",
       "1      1    1      0       1        1        0\n",
       "2      0    0      1       1        1        0\n",
       "3      1    0      1       1        0        0\n",
       "4      0    0      1       1        0        1\n",
       "5      1    0      1       1        0        1\n",
       "6      1    0      0       0        0        1\n",
       "7      1    0      1       1        0        0\n",
       "8      0    1      1       1        0        1\n",
       "9      1    0      1       1        0        0\n",
       "10     1    0      1       1        0        0\n",
       "11     1    0      1       0        1        1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the dataset\n",
    "data = {\n",
    "    \"Milk\":    [1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1],\n",
    "    \"Egg\":     [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    \"Bread\":   [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
    "    \"Butter\":  [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0],\n",
    "    \"Ketchup\": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "    \"Cookies\": [0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1],\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Transaction Dataset:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Apply the Apriori Algorithm**\n",
    "We will use the `mlxtend` library to find frequent itemsets and generate association rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (3.9.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/me/myenv/lib/python3.12/site-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/me/myenv/lib/python3.12/site-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/me/myenv/lib/python3.12/site-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/me/myenv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.4\n"
     ]
    }
   ],
   "source": [
    "! pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets:\n",
      "    support               itemsets\n",
      "0  0.750000                 (Milk)\n",
      "1  0.833333                (Bread)\n",
      "2  0.833333               (Butter)\n",
      "3  0.583333          (Bread, Milk)\n",
      "4  0.583333         (Milk, Butter)\n",
      "5  0.750000        (Bread, Butter)\n",
      "6  0.500000  (Bread, Milk, Butter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me/myenv/lib/python3.12/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Step 1: Generate frequent itemsets with Apriori\n",
    "frequent_itemsets = apriori(df, min_support=0.5, use_colnames=True)\n",
    "\n",
    "# Display frequent itemsets\n",
    "print(\"\\nFrequent Itemsets:\")\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Generate Association Rules**\n",
    "We generate rules based on **confidence** and calculate **lift**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate rules based on confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules:\n",
      "      antecedents consequents   support  confidence      lift\n",
      "0         (Bread)      (Milk)  0.583333    0.700000  0.933333\n",
      "1          (Milk)     (Bread)  0.583333    0.777778  0.933333\n",
      "2        (Butter)      (Milk)  0.583333    0.700000  0.933333\n",
      "3          (Milk)    (Butter)  0.583333    0.777778  0.933333\n",
      "4        (Butter)     (Bread)  0.750000    0.900000  1.080000\n",
      "5         (Bread)    (Butter)  0.750000    0.900000  1.080000\n",
      "6   (Milk, Bread)    (Butter)  0.500000    0.857143  1.028571\n",
      "7  (Butter, Milk)     (Bread)  0.500000    0.857143  1.028571\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate association rules based on confidence\n",
    "rules = association_rules(frequent_itemsets, num_itemsets=len(df), metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Display the rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate rules based on lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules:\n",
      "      antecedents     consequents  support  confidence      lift\n",
      "0        (Butter)         (Bread)     0.75    0.900000  1.080000\n",
      "1         (Bread)        (Butter)     0.75    0.900000  1.080000\n",
      "2   (Milk, Bread)        (Butter)     0.50    0.857143  1.028571\n",
      "3  (Butter, Milk)         (Bread)     0.50    0.857143  1.028571\n",
      "4         (Bread)  (Butter, Milk)     0.50    0.600000  1.028571\n",
      "5        (Butter)   (Milk, Bread)     0.50    0.600000  1.028571\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate association rules based on lift\n",
    "rules = association_rules(frequent_itemsets, num_itemsets=len(df), metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Display the rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. Filter and Interpret Rules**\n",
    "You can filter rules for high lift or specific itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Rules with Lift > 1:\n",
      "      antecedents     consequents  support  confidence      lift\n",
      "0        (Butter)         (Bread)     0.75    0.900000  1.080000\n",
      "1         (Bread)        (Butter)     0.75    0.900000  1.080000\n",
      "2   (Milk, Bread)        (Butter)     0.50    0.857143  1.028571\n",
      "3  (Butter, Milk)         (Bread)     0.50    0.857143  1.028571\n",
      "4         (Bread)  (Butter, Milk)     0.50    0.600000  1.028571\n",
      "5        (Butter)   (Milk, Bread)     0.50    0.600000  1.028571\n"
     ]
    }
   ],
   "source": [
    "# Filter rules with Lift > 1\n",
    "filtered_rules = rules[rules['lift'] > 1]\n",
    "print(\"\\nFiltered Rules with Lift > 1:\")\n",
    "print(filtered_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "1. $ \\text{Milk, Bread} \\rightarrow \\text{Butter} $\n",
    "   - Support = 58%, Confidence = 87.5%, Lift = 1.05.\n",
    "   - Suggest bundling these items for promotions.\n",
    "2. $ \\text{Milk, Butter} \\rightarrow \\text{Bread} $\n",
    "   - Similar metrics as above, showing strong relationships.\n",
    "3. $ \\text{Bread, Butter} \\rightarrow \\text{Milk} $\n",
    "   - High confidence but slightly weaker lift, still actionable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#8F0177;\n",
    "    padding:15px;\n",
    "    border-radius:8px;\n",
    "    color:white;\n",
    "    display:flex;\n",
    "    align-items:center;\n",
    "\">\n",
    "    <h3 style=\"margin:0;\">Two-Items Rules</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If desired, we can focus on association rules where the antecedent (X) contains just **one item** (i.e., 1-item antecedent, 2 items in the rule overall).\n",
    "\n",
    "Consider the rule:\n",
    "\n",
    "$\n",
    "\\text{Milk} \\rightarrow \\text{Bread}\n",
    "$\n",
    "\n",
    "Suppose we have **12 transactions**, and we observe:\n",
    "\n",
    "* **Milk** appears in **9** transactions.\n",
    "* **Milk and Bread together** appear in **7** transactions.\n",
    "\n",
    "Then:\n",
    "\n",
    "* **Support** of the rule is the fraction of all transactions that contain both Milk and Bread:\n",
    "  $\n",
    "  \\text{supp}(\\text{Milk} \\rightarrow \\text{Bread}) = \\frac{7}{12} \\approx 58%.$\n",
    "\n",
    "* **Confidence** of the rule is the fraction of Milk-transactions that also contain Bread:\n",
    "  $\n",
    "  \\text{conf}(\\text{Milk} \\rightarrow \\text{Bread}) = \\frac{7}{9} \\approx 78%.\n",
    "  $\n",
    "\n",
    "So we can write the rule as:\n",
    "\n",
    "$\\text{Milk} \\rightarrow \\text{Bread}$ {S = 58%, C = 78%}.\n",
    "\n",
    "### 2-Item Rules vs 3-Item Rules\n",
    "\n",
    "#### 2-Item Rules (e.g., $\\text{Milk} \\rightarrow \\text{Bread}$)\n",
    "\n",
    "* **Simplicity**: Easy to read, explain, and act on.\n",
    "* **Higher support and confidence (typically)**: Fewer items need to co-occur, so these rules tend to appear more often in the data.\n",
    "* **Broad applicability**: Capture general trends such as\n",
    "  $\n",
    "  \\text{Milk} \\rightarrow \\text{Bread},\n",
    "  $\n",
    "  which can inform store layout (placing items nearby) or simple promotions.\n",
    "\n",
    "#### 3-Item Rules (e.g., $\\text{Milk, Bread} \\rightarrow \\text{Butter}$)\n",
    "\n",
    "* **Deeper insights**: Reveal more specific patterns, like\n",
    "  $\n",
    "  \\text{Milk, Bread} \\rightarrow \\text{Butter}\n",
    "  $\n",
    "  that might not be visible in 2-item rules.\n",
    "* **Lower support (usually)**: All three items must appear together, so these combinations are naturally less frequent.\n",
    "* **Targeted application**: Well-suited for niche marketing, personalized recommendations, or special bundle offers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Is Better?\n",
    "\n",
    "* Use **2-item rules** when you want:\n",
    "\n",
    "  * General trends,\n",
    "  * Simple explanations,\n",
    "  * Broad business strategies (e.g., product placement, popular combos).\n",
    "\n",
    "* Use **3-item rules** when you want:\n",
    "\n",
    "  * More specific patterns,\n",
    "  * Finer-grained understanding of customer behavior,\n",
    "  * Targeted campaigns or tailored bundles.\n",
    "\n",
    "There is no universally “better” rule size—the choice depends on your **data characteristics** (how dense/sparse the transactions are) and your **business objectives** (broad policies vs. targeted actions)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
