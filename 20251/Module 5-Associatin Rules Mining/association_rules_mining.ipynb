{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Alt Text](https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/header.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: flex-start; align-items: center;\">\n",
    "    <a href=\"https://colab.research.google.com/github/msfasha/307304-Data-Mining/blob/main/20251/Module%205-Associatin%20Rules%20Mining/association_rules_mining.ipynb\" target=\"_blank\">\n",
    "        <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" style=\"height: 25px; margin-right: 20px;\">\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Association Rule Mining ‚Äì Market Basket Analysis (MBA)\n",
    "\n",
    "Association rule mining is a data mining technique used to uncover **if‚Äìthen relationships** between items in large datasets, such as retail transaction logs. These relationships, known as **association rules**, capture patterns of items that frequently occur together (called **co-occurrences**).\n",
    "\n",
    "In the context of **market basket analysis**, association rules help answer questions like: *‚ÄúWhich products are often bought together?‚Äù* For example, suppose we find that 75% of customers who buy cereal also buy milk. We can express this as the rule:\n",
    "\n",
    "$\\{\\mathrm{cereal}\\} \\Rightarrow \\{\\mathrm{milk}\\}$\n",
    "\n",
    "This rule suggests that customers who purchase cereal often purchase milk as well. Such insights can guide **marketing and retail decisions**, including promotional strategies, product bundling, and shelf placement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/mba.png\" alt=\"Association Ruels Mining\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/mall_bill.png\" alt=\"Mall Bill\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: flex-start; align-items: center;\">\n",
    "    <a href=\"https://www.youtube.com/watch?v=guVvtZ7ZClw\" target=\"_blank\">\n",
    "        <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/youtube.png\" alt=\"KMeans Youtube Video\" style=\"height: 40px;\">\n",
    "    <a href=\"https://uopstdedu-my.sharepoint.com/:f:/g/personal/mohammed_fasha_uop_edu_jo/EkNUft0LJ_JJg5SdPETsj90BXHoevd0DlMBwDY6Or8YfCw?e=L73iKu\" target=\"_blank\">\n",
    "        <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/video_icon.png\" alt=\"Recorded Video Lecture\" style=\"height: 100px;margin-left:20px;\"\">\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association Rule Use Cases and Domains\n",
    "\n",
    "Association rule mining can be applied in various domains beyond market basket analysis. Here are some examples:\n",
    "\n",
    " 1. **Healthcare**\n",
    "   - **Disease Diagnosis:** Identifying associations between symptoms and diseases. For example, a rule like *{fever, cough} ‚Üí {flu}* can help predict diseases.\n",
    "   - **Drug Interactions:** Discovering relationships between medications that are frequently prescribed together or identifying combinations that lead to adverse reactions.\n",
    "\n",
    " 2. **Web Usage Mining**\n",
    "   - **Website Optimization:** Analyzing user navigation patterns to determine common paths or clicks, e.g., *{homepage ‚Üí product page} ‚Üí {checkout}*.\n",
    "   - **Recommendation Systems:** Suggesting content or products based on frequently co-accessed items, e.g., *{clicked 'smartphone'} ‚Üí {clicked 'smartphone accessories'}*.\n",
    "\n",
    " 3. **Education**\n",
    "   - **Student Behavior Analysis:** Discovering patterns in course enrollment, such as *{math101, cs101} ‚Üí {stat101}*.\n",
    "   - **Learning Paths:** Identifying sequences of topics that students study, helping design better curricula.\n",
    "\n",
    " 4. **Telecommunications**\n",
    "   - **Customer Churn Analysis:** Detecting combinations of usage patterns that are associated with customers leaving the service, e.g., *{low data usage, few calls} ‚Üí {churn}*.\n",
    "   - **Service Bundling:** Identifying services that are commonly purchased together, like *{broadband, mobile} ‚Üí {TV subscription}*.\n",
    "\n",
    " 5. **Banking and Finance**\n",
    "   - **Fraud Detection:** Uncovering patterns associated with fraudulent transactions, e.g., *{high transaction frequency, odd hours} ‚Üí {fraud}*.\n",
    "   - **Loan Approvals:** Identifying attributes of successful loan applications, such as *{high income, good credit score} ‚Üí {loan approved}*.\n",
    "\n",
    " 6. **Manufacturing**\n",
    "   - **Fault Detection:** Identifying combinations of machine conditions that frequently result in faults, e.g., *{high temperature, low pressure} ‚Üí {equipment failure}*.\n",
    "   - **Supply Chain Optimization:** Discovering patterns in material usage, e.g., *{material A, material B} ‚Üí {product C}*.\n",
    "\n",
    " 7. **Retail Beyond Market Basket**\n",
    "   - **Shelf Placement:** Finding products that are often bought together to optimize store layout.\n",
    "   - **Customer Segmentation:** Identifying customer groups with similar purchasing behaviors, e.g., *{frequent discount purchases} ‚Üí {low brand loyalty}*.\n",
    "\n",
    " 8. **Social Media Analysis**\n",
    "   - **Trending Topics:** Discovering associations between hashtags, e.g., *{#climatechange, #sustainability} ‚Üí {#renewableenergy}*.\n",
    "   - **User Behavior Patterns:** Understanding engagement behaviors, such as *{likes post, comments on post} ‚Üí {shares post}*.\n",
    "\n",
    " 9. **Energy Sector**\n",
    "   - **Usage Patterns:** Identifying associations in energy usage, like *{high A/C usage, weekend} ‚Üí {peak energy consumption}*.\n",
    "   - **Smart Grid Analysis:** Detecting patterns for predictive maintenance, e.g., *{low voltage, high demand} ‚Üí {power outage}*.\n",
    "\n",
    " 10. **Transportation and Logistics**\n",
    "   - **Traffic Analysis:** Discovering patterns in traffic conditions, e.g., *{morning rush hour, bad weather} ‚Üí {traffic jam}*.\n",
    "   - **Route Optimization:** Identifying frequently used delivery routes, such as *{route A, route B} ‚Üí {delivered faster}*. \n",
    "\n",
    " 11. **E-commerce**\n",
    "   - **User Preferences:** Identifying patterns in user preferences for personalized recommendations.\n",
    "   - **Cross-Selling:** Suggesting related products based on purchase history.\n",
    "\n",
    " 12. **Sports Analytics**\n",
    "   - **Performance Metrics:** Discovering combinations of player actions that lead to victories, e.g., *{high possession, accurate passes} ‚Üí {win}*.\n",
    "   - **Injury Prevention:** Identifying conditions that precede injuries, such as *{high training load, lack of rest} ‚Üí {injury risk}*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Apriori Algorithm\n",
    "\n",
    "Apriori is a classic algorithm for **finding frequent itemsets** and **deriving association rules** in transactional databases (e.g., shopping baskets, web logs). It is based on the idea that **every subset of a frequent itemset must also be frequent**.\n",
    "\n",
    "**Key points:**\n",
    "\n",
    "* Proposed by **Agrawal & Srikant (1994)**.\n",
    "* Works on **transaction data** (e.g., sets of items bought together).\n",
    "* First finds **frequent single items**, then **grows** them into larger itemsets as long as they remain frequent.\n",
    "* Uses a **bottom-up, level-wise** search with **candidate generation** and testing.\n",
    "* Stops when **no more frequent extensions** can be found.\n",
    "* The resulting frequent itemsets are used to build **association rules** (e.g., for **market basket analysis**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/apriori-algorithm.jpg\" alt=\"Apriori Algorithm\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "............................................................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Association Rules\n",
    "To create association rules, we use 3 metrics:\n",
    "1. Support: finds the popular items and builds initial rules.\n",
    "2. Confidence: Enhance initial rules by finding true relationships.\n",
    "3. Lift: Enhance rules by acomodating for popular items effect (x -> y where x is popular e.g. bread in a bakery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/3_mba_metrics.png\" alt=\"The 3 Metrics of MBA Bill\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Support**: \n",
    "Support is a measure that represents the frequency or proportion of transactions in the dataset that contain a given item set or pattern. In other words, it measures how often a particular combination of items appears together in the dataset. Support is a **Probability Based** measure that has a value between 0 and 1.\n",
    "\n",
    "$ \\text{Support(X)} = \\frac{\\text{Number of transactions containing X}}{\\text{Total transactions}} $\n",
    "\n",
    "  **Valid Values for Support:**\n",
    "  - **Range**: The value of support ranges from **0% to 100%**:\n",
    "  - **0%**: The itemset does not appear in any transaction.\n",
    "  - **100%**: The itemset appears in all transactions.\n",
    "\n",
    "  **Interpreting Support:**\n",
    "  - **High support**: The itemset is common and may represent a strong association.\n",
    "  - **Low support**: The itemset is rare and might not provide actionable insights.\n",
    "\n",
    "**Thresholds in Practice**\n",
    "  - In practice, a minimum support threshold is specified to filter out infrequent itemsets, ensuring only itemsets that appear frequently in the dataset are considered for further analysis.\n",
    "  - Generally speaking, the minimum values for **support**, **confidence**, and **lift** depend on the specific dataset and the business context, but here are some common guidelines and starting points:\n",
    "  - Setting a very high support threshold can exclude less frequent but potentially interesting itemsets.\n",
    "  - If support is too low, the rule may represent rare occurrences, which might not be meaningful or actionable.\n",
    "- **Typical Threshold**: \n",
    "  - **5-10%**: Frequently used in retail datasets where only a small fraction of products are bought together.\n",
    "  - **Higher Thresholds (20-30%)**: For smaller datasets or when focusing on very popular combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Let‚Äôs assume that we have a small dataset with 12 transactions:\n",
    "\n",
    "| **Transaction ID** | **Item 1** | **Item 2** | **Item 3** | **Item 4** | **Item 5** |\n",
    "|---------------------|------------|------------|------------|------------|------------|\n",
    "| 1                   | Milk       | Egg        | Bread      | Butter     |            |\n",
    "| 2                   | Milk       | Butter     | Egg        | Ketchup    |            |\n",
    "| 3                   | Bread      | Butter     | Ketchup    |            |            |\n",
    "| 4                   | Milk       | Bread      | Butter     |            |            |\n",
    "| 5                   | Bread      | Butter     | Cookies    |            |            |\n",
    "| 6                   | Milk       | Bread      | Butter     | Cookies    |            |\n",
    "| 7                   | Milk       | Cookies    |            |            |            |\n",
    "| 8                   | Milk       | Bread      | Butter     |            |            |\n",
    "| 9                   | Bread      | Butter     | Egg        | Cookies    |            |\n",
    "| 10                  | Milk       | Butter     | Bread      |            |            |\n",
    "| 11                  | Milk       | Bread      | Butter     |            |            |\n",
    "| 12                  | Milk       | Bread      | Cookies    | Ketchup    |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First, we set out the **Minimum Support** value to:\n",
    " - 50% (focus on items present in at least half of the transactions), this value can be set to 5% or 10% in real-life situations with large datasets.\n",
    "\n",
    " **Step 1: Dataset Transformation**\n",
    "Convert the dataset into a binary format:\n",
    "\n",
    "| Transaction | Milk | Egg | Bread | Butter | Ketchup | Cookies |\n",
    "|-------------|------|-----|-------|--------|---------|---------|\n",
    "| 1           | 1    | 1   | 1     | 1      | 0       | 0       |\n",
    "| 2           | 1    | 1   | 0     | 1      | 1       | 0       |\n",
    "| 3           | 0    | 0   | 1     | 1      | 1       | 0       |\n",
    "| 4           | 1    | 0   | 1     | 1      | 0       | 0       |\n",
    "| 5           | 0    | 0   | 1     | 1      | 0       | 1       |\n",
    "| 6           | 1    | 0   | 1     | 1      | 0       | 1       |\n",
    "| 7           | 1    | 0   | 0     | 0      | 0       | 1       |\n",
    "| 8           | 1    | 0   | 1     | 1      | 0       | 0       |\n",
    "| 9           | 0    | 1   | 1     | 1      | 0       | 1       |\n",
    "| 10          | 1    | 0   | 1     | 1      | 0       | 0       |\n",
    "| 11          | 1    | 0   | 1     | 1      | 0       | 0       |\n",
    "| 12          | 1    | 0   | 1     | 0      | 1       | 1       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Identify Frequent 1-Itemsets**  \n",
    "The algorithm starts by calculating the support for each single item.\n",
    "\n",
    "| Item     | Support Count | Support (%) | Frequent? |\n",
    "|----------|---------------|-------------|-----------|\n",
    "| Milk     | 9             | 75%         | Yes       |\n",
    "| Egg      | 3             | 25%         | No        |\n",
    "| Bread    | 10            | 83%         | Yes       |\n",
    "| Butter   | 10            | 83%         | Yes       |\n",
    "| Ketchup  | 3             | 25%         | No        |\n",
    "| Cookies  | 5             | 42%         | No        |\n",
    "\n",
    "**Frequent 1-itemsets**: `{Milk}`, `{Bread}`, `{Butter}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Generate 2-Itemsets**  \n",
    "Now, combine frequent 1-itemsets into 2-itemsets and calculate their support.\n",
    "\n",
    "| Itemset           | Support Count | Support (%) | Frequent? |\n",
    "|--------------------|---------------|-------------|-----------|\n",
    "| {Milk, Bread}     | 7             | 58%         | Yes       |\n",
    "| {Milk, Butter}    | 7             | 58%         | Yes       |\n",
    "| {Bread, Butter}   | 9             | 75%         | Yes       |\n",
    "\n",
    "**Frequent 2-itemsets**: `{Milk, Bread}`, `{Milk, Butter}`, `{Bread, Butter}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Generate 3-Itemsets**  \n",
    "Combine frequent 2-itemsets into 3-itemsets and calculate their support.\n",
    "\n",
    "| Itemset                   | Support Count | Support (%) | Frequent? |\n",
    "|----------------------------|---------------|-------------|-----------|\n",
    "| {Milk, Bread, Butter}     | 6             | 50%         | Yes       |\n",
    "\n",
    "**Frequent 3-itemset**: `{Milk, Bread, Butter}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: No Larger Itemsets Can Be Created**  \n",
    "Since there are no frequent 4-itemsets (support would drop below 50%), we stop here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Step 6: Generate Initial Association Rules**\n",
    "\n",
    "Now, use the frequent itemsets to generate association rules, we will focus on the largest item set, we can create rules from smaller ones if needed.\n",
    "\n",
    "Rules from `{Milk, Bread, Butter}`:\n",
    "1. **Rule 1**: $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$  \n",
    "\n",
    "$$Support =  P(\\text{Milk, Bread, Butter}) = 6/12 = 50\\% $$\n",
    "\n",
    "1. **Rule 2**: $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$  \n",
    "\n",
    "$$ Support = P(\\text{Milk, Bread, Butter}) = 6/12 = 50\\% $$\n",
    "\n",
    "2. **Rule 3**: $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$  \n",
    "\n",
    "$$ Support = P(\\text{Milk, Bread, Butter}) = 6/12 = 50\\% $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Problem with Support**\n",
    "\n",
    "Support is useful, but it has a limitation: it is **symmetric**.  \n",
    "\n",
    "$\\text{Support}(\\text{milk} \\cap \\text{diapers})$ is exactly the same whether we write the rule as\n",
    "$(\\text{Milk} \\rightarrow \\text{Diapers})$ or $(\\text{Diapers} \\rightarrow \\text{Milk})$. It only tells us **how often the two items appear together**, not **in which direction the rule should go**. \n",
    "\n",
    "In our example with 1,000 transactions, milk and diapers appear together in 100 of them, so\n",
    "$\n",
    "\\text{support}(\\text{milk} \\cap \\text{diapers}) = 100/1000 = 10%.\n",
    "$\n",
    "\n",
    "That 10% tells us the pair is reasonably common, but it does **not** answer a key business question: *Should we recommend milk to customers who buy diapers, or recommend diapers to customers who buy milk, or both?*\n",
    "\n",
    "Support alone cannot distinguish between these options because it treats the pair $({\\text{milk}, \\text{diapers}})$ the same in both directions.\n",
    "\n",
    "This is why we need **confidence**, which is directional and based on **conditional probability**.  \n",
    "\n",
    "From the raw data: 500 customers bought milk, 150 bought diapers, and 100 bought both. If we look at the rule $(\\text{Diapers} \\rightarrow \\text{Milk})$, the confidence is:  \n",
    "\n",
    "$\n",
    "\\text{conf}(\\text{Milk} \\mid \\text{Diapers}) = 100/150 \\approx 66%,\n",
    "$  \n",
    "\n",
    "meaning 66% of diaper-buyers also buy milk. For the opposite rule $(\\text{Milk} \\rightarrow \\text{Diapers})$, the confidence is:  \n",
    "\n",
    "$\n",
    "\\text{conf}(\\text{Diapers} \\mid \\text{Milk}) = 100/500 = 20%,\n",
    "$  \n",
    "so only 20% of milk-buyers also buy diapers. \n",
    "\n",
    "Now we can clearly see that **Diapers ‚Üí Milk** is the more useful rule. In short: support tells us that the pair is common, but because it is **symmetric**, it cannot guide us on *direction*; confidence is needed to decide which way the rule should go.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More Examples about The Asymmetry of Association Rules:  \n",
    "| Domain             | Rule A ‚Üí B (Strong)                                  | Rule B ‚Üí A (Weak or Misleading)                      | Reason for Asymmetry                                        |\n",
    "| ------------------ | ---------------------------------------------------- | ---------------------------------------------------- | ----------------------------------------------------------- |\n",
    "| Retail             | Buys Smartphone ‚Üí Buys Phone Case                    | Buys Phone Case ‚Üí Buys Smartphone                    | Cases are often bought later or as replacements             |\n",
    "| Web Analytics      | Visits Product Page ‚Üí Adds to Cart                   | Adds to Cart ‚Üí Visits Product Page                   | Visit is required, but not all visits lead to cart          |\n",
    "| Healthcare         | Diagnosed with Diabetes ‚Üí Prescribed Insulin         | Prescribed Insulin ‚Üí Diagnosed with Diabetes         | Insulin used for other conditions too                       |\n",
    "| Fraud Detection    | Unusual Login ‚Üí Account Lock                         | Account Lock ‚Üí Unusual Login                         | Locks triggered by various issues                           |\n",
    "| E-Learning         | Watches Lecture Video ‚Üí Submits Homework             | Submits Homework ‚Üí Watches Lecture Video             | Some students skip the video                                |\n",
    "| Streaming Services | Subscribes to Premium Plan ‚Üí Watches Exclusive Shows | Watches Exclusive Shows ‚Üí Subscribes to Premium Plan | Content may be shared or watched via someone else's account |\n",
    "| Finance            | Misses Loan Payment ‚Üí Credit Score Drops             | Credit Score Drops ‚Üí Misses Loan Payment             | Scores drop for many other financial behaviors              |\n",
    "| HR / Workforce     | Attends Training ‚Üí Improved Job Performance          | Improved Job Performance ‚Üí Attended Training         | Performance may improve for unrelated reasons               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2 Confidence**:\n",
    "In order to validate which rule is correct, we need to examine the confidence of the rule, for example, we might have a frequent item set that have two items (Milk, Bread), we can establish two rules from that set:\n",
    "$$ \\text{Milk} \\rightarrow \\text{Bread} $$\n",
    "$$ \\text{Bread} \\rightarrow \\text{Milk} $$\n",
    "\n",
    "To determine which rule is correct for that frequenct item set (the rule that says when x occurs y also most probably occurs), we can use to confidence establish that assertion.\n",
    "\n",
    "**Confidence** in Apriori is a measure that calculates the **probability** of the rule being true, in other words, it measures the reliability of the rule. Having higher confidence means that when the antecedent occurs, the consequent is likely to follow.\n",
    "     $$ \\text{Confidence(X ‚Üí Y)} = \\frac{\\text{Support(X ‚à© Y)}}{\\text{Support(X)}} $$\n",
    "\n",
    "**Valid Values for Confidence**\n",
    "- **Range**: Confidence values range from **0 to 1**:\n",
    "  - **0**: The rule $ X \\rightarrow Y $ never holds true.\n",
    "  - **1**: The rule $ X \\rightarrow Y $ always holds true (perfect confidence).\n",
    "\n",
    "**Interpreting Confidence**\n",
    "1. **High Confidence ($ \\approx 1 $)**:\n",
    "   - Indicates that $ Y $ almost always occurs when $ X $ occurs.\n",
    "   - Example: If $ X = \\{\\text{bread}\\} $ and $ Y = \\{\\text{butter}\\} $, a high confidence implies that customers buying bread are very likely to buy butter.\n",
    "\n",
    "2. **Low Confidence ($ \\approx 0 $)**:\n",
    "   - Indicates that $ Y $ rarely occurs when $ X $ occurs.\n",
    "   - Example: If $ X = \\{\\text{bread}\\} $ and $ Y = \\{\\text{cereal}\\} $, a low confidence implies that buying bread is not strongly associated with buying cereal.\n",
    "\n",
    "**Thresholds in Practice**\n",
    "\n",
    "The minimum values for **confidence** depend on the specific dataset and the business context, but here are some common guidelines and starting points:\n",
    "- **Typical Threshold**: \n",
    "  - **70-80%**: Commonly used as a starting point for reliable rules.\n",
    "  - Adjust based on your use case:\n",
    "    - Lower threshold (50-60%) for exploratory insights.\n",
    "    - Higher threshold (90%+) for high-accuracy recommendations.\n",
    "- **Reason**: Rules with low confidence may not reliably predict the consequent item, making them less actionable.\n",
    "\n",
    "**Example**:  \n",
    "A rule with 30% confidence means that only 30% of the time, the consequent is bought when the antecedent is bought. This may not justify a marketing strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Step 7: Validate the Rules using Confidence**\n",
    "\n",
    "First, let us set the **Minimum Confidence** value to: 70%.\n",
    "\n",
    "Rules from `{Milk, Bread, Butter}`:\n",
    "1. **Rule 1**: $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$  \n",
    "   \n",
    "$$Confidence = P(\\text{Butter}|\\text{Milk, Bread}) = \\frac{P(\\text{Milk, Bread, Butter})}{P(\\text{Milk, Bread})} = \\frac{6}{7} = 85\\%\n",
    "     $$\n",
    "\n",
    "1. **Rule 2**: $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$  \n",
    "   \n",
    "$$Confidence = P(\\text{Bread}|\\text{Milk, Butter}) = \\frac{P(\\text{Milk, Bread, Butter})}{P(\\text{Milk, Butter})} = \\frac{6}{7} = 85\\%\n",
    "     $$\n",
    "\n",
    "1. **Rule 3**: $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$  \n",
    "   \n",
    "$$Confidence = P(\\text{Milk}|\\text{Bread, Butter}) = \\frac{P(\\text{Milk, Bread, Butter})}{P(\\text{Bread, Butter})} = \\frac{6}{9} \\approx 66\\%\n",
    "     $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.3. Lift Metric**\n",
    "\n",
    "**Confidence alone can be misleading**, especially when the consequent (Y) is very frequent in the dataset. In that case, a rule (X \\Rightarrow Y) may have high confidence simply because (Y) is common, not because there is a strong dependency between (X) and (Y).\n",
    "\n",
    "**Example (bakery: cake and bread)**  \n",
    "Suppose we analyze orders in a bakery and find:\n",
    "\n",
    "* 80% of all orders contain **bread**.\n",
    "* 20% of all orders contain **cake**.\n",
    "* 16% of all orders contain **both cake and bread**.\n",
    "\n",
    "Then the confidence of the rule\n",
    "$\\text{cake} \\Rightarrow \\text{bread}$ is:  \n",
    "$\\text{conf}(\\text{cake} \\Rightarrow \\text{bread})\n",
    "  = \\frac{P(\\text{cake} \\cap \\text{bread})}{P(\\text{cake})}\n",
    "  = \\frac{0.16}{0.20}\n",
    "  = 0.8.$\n",
    "\n",
    "A confidence of **80%** sounds strong, but notice that **bread is already in 80% of all orders**. So customers who buy cake are **not more likely** to buy bread than an average customer‚Äîbread is just very common in the bakery.\n",
    "\n",
    "To address this limitation, we use additional measures such as **lift** alongside confidence.  \n",
    "\n",
    "**Lift** compares $P(Y \\mid X)$ to the overall frequency $P(Y)$:  \n",
    "\n",
    "$\n",
    "\\text{Lift}(X \\Rightarrow Y)\n",
    "= \\frac{\\text{Confidence}(X \\Rightarrow Y)}{\\text{Support}(Y)}\n",
    "= \\frac{P(Y \\mid X)}{P(Y)}.\n",
    "$\n",
    "\n",
    "In other words, Lift measures how likely \n",
    "ùëå is when ùëã happens, compared to how likely ùëå is in general.\n",
    "\n",
    "Equivalently, in terms of supports:  \n",
    "\n",
    "$\n",
    "\\text{Lift}(X \\Rightarrow Y)\n",
    "= \\frac{\\text{Support}(X \\cap Y)}{\\text{Support}(X) \\times \\text{Support}(Y)}.\n",
    "$\n",
    "\n",
    "In the example:  \n",
    "\n",
    "$\n",
    "\\text{lift}(\\text{cake} \\Rightarrow \\text{bread})\n",
    "= \\frac{P(\\text{bread} \\mid \\text{cake})}{P(\\text{bread})}\n",
    "= \\frac{0.8}{0.8}\n",
    "= 1,\n",
    "$\n",
    "\n",
    "which indicates **no real association** beyond what we‚Äôd expect by chance.\n",
    "\n",
    "So lift tells us whether items co-occur more (or less) frequently than chance, making it a useful complement to confidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpreting Lift**\n",
    "\n",
    "Lift measures how strongly two items or itemsets are associated:\n",
    "\n",
    "* $(\\text{lift} > 1)$: items occur together **more often than expected** (positive association).\n",
    "* $(\\text{lift} = 1)$: items occur together **as often as expected** under independence (no association).\n",
    "* $(\\text{lift} < 1)$: items occur together **less often than expected** (negative association).\n",
    "\n",
    "So lift tells us whether items co-occur more (or less) frequently than expected under independence, making it a useful complement to confidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Step 8: Validate Rules using the Lift**\n",
    "\n",
    "First, we set the **Lift > 1** for actionable rules\n",
    "\n",
    "1. **Rule 1**: $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$  \n",
    "   \n",
    "     $$\n",
    "     \\text{Lift} = \\frac{P(\\text{Butter}|\\text{Milk, Bread})}{P(\\text{Butter})} = \\frac{0.85}{0.83} \\approx 1.02\n",
    "     $$\n",
    "\n",
    "2. **Rule 2**: $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$  \n",
    "\n",
    "     $$\n",
    "     \\text{Lift} = \\frac{P(\\text{Bread}|\\text{Milk, Butter})}{P(\\text{Bread})} = \\frac{0.85}{0.83} \\approx 1.02\n",
    "     $$\n",
    "\n",
    "3. **Rule 3**: $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$  \n",
    "   \n",
    "     $$\n",
    "     \\text{Lift} = \\frac{P(\\text{Milk}|\\text{Bread, Butter})}{P(\\text{Milk})} = \\frac{0.66}{0.75} \\approx .88\n",
    "     $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Final Results**\n",
    "\n",
    "Frequent Itemsets:\n",
    "- **1-itemsets**: `{Milk}`, `{Bread}`, `{Butter}`\n",
    "- **2-itemsets**: `{Milk, Bread}`, `{Milk, Butter}`, `{Bread, Butter}`\n",
    "- **3-itemset**: `{Milk, Bread, Butter}`\n",
    "\n",
    "Rules:\n",
    "| Rule                           | Support | Confidence | Lift  | Actionable? |\n",
    "|--------------------------------|---------|------------|-------|-------------|\n",
    "| $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$ | 50%     | 85%      | 1.02  | Yes         |\n",
    "| $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$ | 50%     | 85%      | 1.02  | Yes         |\n",
    "| $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$ | 50%     | 66%      | .88  | No         |\n",
    "\n",
    "**Interpretation and Actionable Insights**\n",
    "| Rule                           | Explaniation |\n",
    "|--------------------------------|--------------|\n",
    "| $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$ |Customers buying Milk and Bread are highly likely (85%) to also buy Butter. Consider bundling these items.         |\n",
    "| $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$ | Strong association; placing these items together could increase sales.         |\n",
    "| $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$ | Suggests that Milk is a complementary product to Bread and Butter, Weak lift thought         |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Python Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement the **Apriori algorithm** using the **`mlxtend`** library for frequent itemset mining and rule generation.\n",
    "\n",
    "**a. Install Required Libraries**\n",
    "Make sure you have the required libraries installed:\n",
    "```bash\n",
    "pip install pandas mlxtend\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Load the Dataset**\n",
    "We will represent the dataset as a **binary transaction matrix** where each row is a transaction, and each column is an item (1 = purchased, 0 = not purchased)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Milk</th>\n",
       "      <th>Egg</th>\n",
       "      <th>Bread</th>\n",
       "      <th>Butter</th>\n",
       "      <th>Ketchup</th>\n",
       "      <th>Cookies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Milk  Egg  Bread  Butter  Ketchup  Cookies\n",
       "0      1    1      1       1        0        0\n",
       "1      1    1      0       1        1        0\n",
       "2      0    0      1       1        1        0\n",
       "3      1    0      1       1        0        0\n",
       "4      0    0      1       1        0        1\n",
       "5      1    0      1       1        0        1\n",
       "6      1    0      0       0        0        1\n",
       "7      1    0      1       1        0        0\n",
       "8      0    1      1       1        0        1\n",
       "9      1    0      1       1        0        0\n",
       "10     1    0      1       1        0        0\n",
       "11     1    0      1       0        1        1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the dataset\n",
    "data = {\n",
    "    \"Milk\":    [1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1],\n",
    "    \"Egg\":     [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    \"Bread\":   [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
    "    \"Butter\":  [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0],\n",
    "    \"Ketchup\": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "    \"Cookies\": [0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1],\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Transaction Dataset:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Apply the Apriori Algorithm**\n",
    "We will use the `mlxtend` library to find frequent itemsets and generate association rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (3.9.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/me/myenv/lib/python3.12/site-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/me/myenv/lib/python3.12/site-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/me/myenv/lib/python3.12/site-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/me/myenv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.4\n"
     ]
    }
   ],
   "source": [
    "! pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets:\n",
      "    support               itemsets\n",
      "0  0.750000                 (Milk)\n",
      "1  0.833333                (Bread)\n",
      "2  0.833333               (Butter)\n",
      "3  0.583333          (Bread, Milk)\n",
      "4  0.583333         (Milk, Butter)\n",
      "5  0.750000        (Bread, Butter)\n",
      "6  0.500000  (Bread, Milk, Butter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me/myenv/lib/python3.12/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Step 1: Generate frequent itemsets with Apriori\n",
    "frequent_itemsets = apriori(df, min_support=0.5, use_colnames=True)\n",
    "\n",
    "# Display frequent itemsets\n",
    "print(\"\\nFrequent Itemsets:\")\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Generate Association Rules**\n",
    "We generate rules based on **confidence** and calculate **lift**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate rules based on confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules:\n",
      "      antecedents consequents   support  confidence      lift\n",
      "0         (Bread)      (Milk)  0.583333    0.700000  0.933333\n",
      "1          (Milk)     (Bread)  0.583333    0.777778  0.933333\n",
      "2        (Butter)      (Milk)  0.583333    0.700000  0.933333\n",
      "3          (Milk)    (Butter)  0.583333    0.777778  0.933333\n",
      "4        (Butter)     (Bread)  0.750000    0.900000  1.080000\n",
      "5         (Bread)    (Butter)  0.750000    0.900000  1.080000\n",
      "6   (Milk, Bread)    (Butter)  0.500000    0.857143  1.028571\n",
      "7  (Butter, Milk)     (Bread)  0.500000    0.857143  1.028571\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate association rules based on confidence\n",
    "rules = association_rules(frequent_itemsets, num_itemsets=len(df), metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Display the rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate rules based on lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules:\n",
      "      antecedents     consequents  support  confidence      lift\n",
      "0        (Butter)         (Bread)     0.75    0.900000  1.080000\n",
      "1         (Bread)        (Butter)     0.75    0.900000  1.080000\n",
      "2   (Milk, Bread)        (Butter)     0.50    0.857143  1.028571\n",
      "3  (Butter, Milk)         (Bread)     0.50    0.857143  1.028571\n",
      "4         (Bread)  (Butter, Milk)     0.50    0.600000  1.028571\n",
      "5        (Butter)   (Milk, Bread)     0.50    0.600000  1.028571\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate association rules based on lift\n",
    "rules = association_rules(frequent_itemsets, num_itemsets=len(df), metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Display the rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. Filter and Interpret Rules**\n",
    "You can filter rules for high lift or specific itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Rules with Lift > 1:\n",
      "      antecedents     consequents  support  confidence      lift\n",
      "0        (Butter)         (Bread)     0.75    0.900000  1.080000\n",
      "1         (Bread)        (Butter)     0.75    0.900000  1.080000\n",
      "2   (Milk, Bread)        (Butter)     0.50    0.857143  1.028571\n",
      "3  (Butter, Milk)         (Bread)     0.50    0.857143  1.028571\n",
      "4         (Bread)  (Butter, Milk)     0.50    0.600000  1.028571\n",
      "5        (Butter)   (Milk, Bread)     0.50    0.600000  1.028571\n"
     ]
    }
   ],
   "source": [
    "# Filter rules with Lift > 1\n",
    "filtered_rules = rules[rules['lift'] > 1]\n",
    "print(\"\\nFiltered Rules with Lift > 1:\")\n",
    "print(filtered_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "1. $ \\text{Milk, Bread} \\rightarrow \\text{Butter} $\n",
    "   - Support = 58%, Confidence = 87.5%, Lift = 1.05.\n",
    "   - Suggest bundling these items for promotions.\n",
    "2. $ \\text{Milk, Butter} \\rightarrow \\text{Bread} $\n",
    "   - Similar metrics as above, showing strong relationships.\n",
    "3. $ \\text{Bread, Butter} \\rightarrow \\text{Milk} $\n",
    "   - High confidence but slightly weaker lift, still actionable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-Item Rules\n",
    "\n",
    "If desired, we can focus on association rules where the antecedent (X) contains just **one item** (i.e., 1-item antecedent, 2 items in the rule overall).\n",
    "\n",
    "Consider the rule:\n",
    "\n",
    "$\n",
    "\\text{Milk} \\rightarrow \\text{Bread}\n",
    "$\n",
    "\n",
    "Suppose we have **12 transactions**, and we observe:\n",
    "\n",
    "* **Milk** appears in **9** transactions.\n",
    "* **Milk and Bread together** appear in **7** transactions.\n",
    "\n",
    "Then:\n",
    "\n",
    "* **Support** of the rule is the fraction of all transactions that contain both Milk and Bread:\n",
    "  $\n",
    "  \\text{supp}(\\text{Milk} \\rightarrow \\text{Bread}) = \\frac{7}{12} \\approx 58%.$\n",
    "\n",
    "* **Confidence** of the rule is the fraction of Milk-transactions that also contain Bread:\n",
    "  $\n",
    "  \\text{conf}(\\text{Milk} \\rightarrow \\text{Bread}) = \\frac{7}{9} \\approx 78%.\n",
    "  $\n",
    "\n",
    "So we can write the rule as:\n",
    "\n",
    "$\\text{Milk} \\rightarrow \\text{Bread}$ {S = 58%, C = 78%}.\n",
    "\n",
    "### 2-Item Rules vs 3-Item Rules\n",
    "\n",
    "#### 2-Item Rules (e.g., $\\text{Milk} \\rightarrow \\text{Bread}$)\n",
    "\n",
    "* **Simplicity**: Easy to read, explain, and act on.\n",
    "* **Higher support and confidence (typically)**: Fewer items need to co-occur, so these rules tend to appear more often in the data.\n",
    "* **Broad applicability**: Capture general trends such as\n",
    "  $\n",
    "  \\text{Milk} \\rightarrow \\text{Bread},\n",
    "  $\n",
    "  which can inform store layout (placing items nearby) or simple promotions.\n",
    "\n",
    "#### 3-Item Rules (e.g., $\\text{Milk, Bread} \\rightarrow \\text{Butter}$)\n",
    "\n",
    "* **Deeper insights**: Reveal more specific patterns, like\n",
    "  $\n",
    "  \\text{Milk, Bread} \\rightarrow \\text{Butter}\n",
    "  $\n",
    "  that might not be visible in 2-item rules.\n",
    "* **Lower support (usually)**: All three items must appear together, so these combinations are naturally less frequent.\n",
    "* **Targeted application**: Well-suited for niche marketing, personalized recommendations, or special bundle offers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Is Better?\n",
    "\n",
    "* Use **2-item rules** when you want:\n",
    "\n",
    "  * General trends,\n",
    "  * Simple explanations,\n",
    "  * Broad business strategies (e.g., product placement, popular combos).\n",
    "\n",
    "* Use **3-item rules** when you want:\n",
    "\n",
    "  * More specific patterns,\n",
    "  * Finer-grained understanding of customer behavior,\n",
    "  * Targeted campaigns or tailored bundles.\n",
    "\n",
    "There is no universally ‚Äúbetter‚Äù rule size‚Äîthe choice depends on your **data characteristics** (how dense/sparse the transactions are) and your **business objectives** (broad policies vs. targeted actions)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
