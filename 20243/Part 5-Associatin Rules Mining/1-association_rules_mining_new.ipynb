{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Alt Text](https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/header.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: flex-start; align-items: center;\">\n",
    "    <a href=\"https://colab.research.google.com/github/msfasha/307304-Data-Mining/blob/main/20243/Part%205-Associatin%20Rules%20Mining/1-association_rules_mining.ipynb\" target=\"_blank\">\n",
    "        <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" style=\"height: 25px; margin-right: 20px;\">\n",
    "    </a>\n",
    "    <a href=\"https://www.youtube.com/watch?v=guVvtZ7ZClw\" target=\"_blank\">\n",
    "        <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/youtube.png\" alt=\"KMeans Youtube Video\" style=\"height: 40px;\">\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Introduction to Association Rule Mining - Market Baset Analysis (MBA)\n",
    "\n",
    "- Association rules are **if-then** statements that show **the probability of relationships** between data items within large data sets in various types of databases. \n",
    "- At a basic level, association rule mining involves the use of machine learning models to analyze data for patterns, called **co-occurrences**, in a database. \n",
    "- It identifies **frequent if-then associations**, which themselves are the association rules.\n",
    "- For example, if 75% of people who buy cereal also buy milk, then there is an evidence for pattern in the transactional data that customers who buy cereal often buy milk. \n",
    "\n",
    "For example, the rule:\n",
    "\n",
    "$$\\displaystyle \\{\\mathrm {cereal} \\}\\Rightarrow \\{\\mathrm {milk} \\}$$\n",
    "\n",
    "Such information can be used as the basis for decisions about marketing activities such as, e.g., promotional pricing or product placements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/mba.png\" alt=\"Association Ruels Mining\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/msfasha/307304-Data-Mining/main/images/mall_bill.png\" alt=\"Mall Bill\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Apriori Algorithm\n",
    "Apriori is the most common algorithm used for MBA. It identifies frequent itemsets and builds association rules from them by leveraging the principle that **subsets of frequent itemsets must also be frequent.**\n",
    "### Key Notes:\n",
    "- Apriori is an algorithm for identifying frequent item-sets and association rule learning over relational databases. \n",
    "- It was proposed by Agrawal and Srikant in 1994.\n",
    "- Apriori is designed to operate on databases containing transactions (for example, collections of items bought by customers, or details of a website frequentation or IP addresses). \n",
    "- It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database. \n",
    "- The frequent item sets determined by Apriori can be used to determine association rules which highlight general trends in the database.\n",
    "- This has applications in domains such as market basket analysis.\n",
    "- Apriori uses a \"bottom up\" approach, where frequent subsets are extended one item at a time (a step known as candidate generation), and groups of candidates are tested against the data. \n",
    "- The algorithm terminates when no further successful extensions are found.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "............................................................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Association Rules\n",
    "To create association rules, we use 3 metrics:\n",
    "1. Support: finds the popular items and builds initial rules.\n",
    "2. Confidence: Enhance initial rules by finding true relationships.\n",
    "3. Lift: Enhance rules by acomodating for popular items effect (x -> y where x is popular e.g. bread in a bakery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Support**: \n",
    "Support is a measure that represents the frequency or proportion of transactions in the dataset that contain a given item set or pattern. In other words, it measures how often a particular combination of items appears together in the dataset. Support is a **Probability Based** measure that has a value between 0 and 1.\n",
    "     $$ \\text{Support(X)} = \\frac{\\text{Number of transactions containing X}}{\\text{Total transactions}} $$\n",
    "\n",
    "  **Valid Values for Support:**\n",
    "  - **Range**: The value of support ranges from **0% to 100%**:\n",
    "  - **0%**: The itemset does not appear in any transaction.\n",
    "  - **100%**: The itemset appears in all transactions.\n",
    "\n",
    "  **Interpreting Support:**\n",
    "  - **High support**: The itemset is common and may represent a strong association.\n",
    "  - **Low support**: The itemset is rare and might not provide actionable insights.\n",
    "\n",
    "**Thresholds in Practice**\n",
    "  - In practice, a minimum support threshold is specified to filter out infrequent itemsets, ensuring only itemsets that appear frequently in the dataset are considered for further analysis.\n",
    "  - Generally speaking, the minimum values for **support**, **confidence**, and **lift** depend on the specific dataset and the business context, but here are some common guidelines and starting points:\n",
    "  - Setting a very high support threshold can exclude less frequent but potentially interesting itemsets.\n",
    "  - If support is too low, the rule may represent rare occurrences, which might not be meaningful or actionable.\n",
    "- **Typical Threshold**: \n",
    "  - **5-10%**: Frequently used in retail datasets where only a small fraction of products are bought together.\n",
    "  - **Higher Thresholds (20-30%)**: For smaller datasets or when focusing on very popular combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practical Example\n",
    "\n",
    "Let’s assume a small dataset with 12 transactions:\n",
    "\n",
    "| **Transaction ID** | **Item 1** | **Item 2** | **Item 3** | **Item 4** | **Item 5** |\n",
    "|---------------------|------------|------------|------------|------------|------------|\n",
    "| 1                   | Milk       | Egg        | Bread      | Butter     |            |\n",
    "| 2                   | Milk       | Butter     | Egg        | Ketchup    |            |\n",
    "| 3                   | Bread      | Butter     | Ketchup    |            |            |\n",
    "| 4                   | Milk       | Bread      | Butter     |            |            |\n",
    "| 5                   | Bread      | Butter     | Cookies    |            |            |\n",
    "| 6                   | Milk       | Bread      | Butter     | Cookies    |            |\n",
    "| 7                   | Milk       | Cookies    |            |            |            |\n",
    "| 8                   | Milk       | Bread      | Butter     |            |            |\n",
    "| 9                   | Bread      | Butter     | Egg        | Cookies    |            |\n",
    "| 10                  | Milk       | Butter     | Bread      |            |            |\n",
    "| 11                  | Milk       | Bread      | Butter     |            |            |\n",
    "| 12                  | Milk       | Bread      | Cookies    | Ketchup    |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We set out thresholds as following:\n",
    "- **Minimum Support**: 50% (focus on items present in at least half of the transactions), this value can be set to 5% or 10% in real-life situations with large datasets.\n",
    "- **Minimum Confidence**: 70%.\n",
    "- **Lift**: Lift > 1 for actionable rules.\n",
    "\n",
    " **Step 1: Dataset Transformation**\n",
    "Convert the dataset into a binary format:\n",
    "\n",
    "| Transaction | Milk | Egg | Bread | Butter | Ketchup | Cookies |\n",
    "|-------------|------|-----|-------|--------|---------|---------|\n",
    "| 1           | 1    | 1   | 1     | 1      | 0       | 0       |\n",
    "| 2           | 1    | 1   | 0     | 1      | 1       | 0       |\n",
    "| 3           | 0    | 0   | 1     | 1      | 1       | 0       |\n",
    "| 4           | 1    | 0   | 1     | 1      | 0       | 0       |\n",
    "| 5           | 0    | 0   | 1     | 1      | 0       | 1       |\n",
    "| 6           | 1    | 0   | 1     | 1      | 0       | 1       |\n",
    "| 7           | 1    | 0   | 0     | 0      | 0       | 1       |\n",
    "| 8           | 1    | 0   | 1     | 1      | 0       | 0       |\n",
    "| 9           | 0    | 1   | 1     | 1      | 0       | 1       |\n",
    "| 10          | 1    | 0   | 1     | 1      | 0       | 0       |\n",
    "| 11          | 1    | 0   | 1     | 1      | 0       | 0       |\n",
    "| 12          | 1    | 0   | 1     | 0      | 1       | 1       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Identify Frequent 1-Itemsets**\n",
    "The algorithm starts by calculating the support for each single item.\n",
    "\n",
    "| Item     | Support Count | Support (%) | Frequent? |\n",
    "|----------|---------------|-------------|-----------|\n",
    "| Milk     | 9             | 75%         | Yes       |\n",
    "| Egg      | 3             | 25%         | No        |\n",
    "| Bread    | 10            | 83%         | Yes       |\n",
    "| Butter   | 10            | 83%         | Yes       |\n",
    "| Ketchup  | 3             | 25%         | No        |\n",
    "| Cookies  | 5             | 42%         | No        |\n",
    "\n",
    "**Frequent 1-itemsets**: `{Milk}`, `{Bread}`, `{Butter}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Generate 2-Itemsets**\n",
    "Now, combine frequent 1-itemsets into 2-itemsets and calculate their support.\n",
    "\n",
    "| Itemset           | Support Count | Support (%) | Frequent? |\n",
    "|--------------------|---------------|-------------|-----------|\n",
    "| {Milk, Bread}     | 7             | 58%         | Yes       |\n",
    "| {Milk, Butter}    | 7             | 58%         | Yes       |\n",
    "| {Bread, Butter}   | 9             | 75%         | Yes       |\n",
    "\n",
    "**Frequent 2-itemsets**: `{Milk, Bread}`, `{Milk, Butter}`, `{Bread, Butter}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Generate 3-Itemsets**\n",
    "Combine frequent 2-itemsets into 3-itemsets and calculate their support.\n",
    "\n",
    "| Itemset                   | Support Count | Support (%) | Frequent? |\n",
    "|----------------------------|---------------|-------------|-----------|\n",
    "| {Milk, Bread, Butter}     | 6             | 50%         | Yes       |\n",
    "\n",
    "**Frequent 3-itemset**: `{Milk, Bread, Butter}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: No Larger Itemsets Can Be Created**\n",
    "Since there are no frequent 4-itemsets (support would drop below 50%), we stop here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Step 6: Generate Association Rules**\n",
    "\n",
    "Now, use the frequent itemsets to generate association rules, we will focus on the largest item set, we can create rules from smaller ones if needed.\n",
    "\n",
    "Rules from `{Milk, Bread, Butter}`:\n",
    "1. **Rule 1**: $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$\n",
    "   - **Support**: $$ P(\\text{Milk, Bread, Butter}) = 6/12 = 50\\% $$\n",
    "\n",
    "2. **Rule 2**: $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$\n",
    "   - **Support**: $$ P(\\text{Milk, Bread, Butter}) = 6/12 = 50\\% $$\n",
    "\n",
    "3. **Rule 3**: $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$\n",
    "   - **Support**: $$ P(\\text{Milk, Bread, Butter}) = 6/12 = 50\\% $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the supprt for all values is the same, now we need to use **confidence and lift** to enhance these initial rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2 Confidence**:\n",
    "In order to validate which rule is correct, we need to examin the confidence of the rule, for example, we might have a frequent item set that have two items (Milk, Bread), we can establish two rules from that set:\n",
    "$$ \\text{Milk} \\rightarrow \\text{Bread} $$\n",
    "$$ \\text{Bread} \\rightarrow \\text{Milk} $$\n",
    "\n",
    "To determine which rule is correct for that frequenct item set (the rule that says when x occurs y also most probably occurs), we can use confidence to confidence establish that assertion.\n",
    "\n",
    "**Confidence** in Apriori is a measure that calculates the **probability** of the rule being true, in other words, it measures the reliability of the rule. Having higher confidence means that when the antecedent occurs, the consequent is likely to follow.\n",
    "     $$ \\text{Confidence(X → Y)} = \\frac{\\text{Support(X ∩ Y)}}{\\text{Support(X)}} $$\n",
    "\n",
    "**Valid Values for Confidence**\n",
    "- **Range**: Confidence values range from **0 to 1**:\n",
    "  - **0**: The rule $ X \\rightarrow Y $ never holds true.\n",
    "  - **1**: The rule $ X \\rightarrow Y $ always holds true (perfect confidence).\n",
    "\n",
    "**Interpreting Confidence**\n",
    "1. **High Confidence ($ \\approx 1 $)**:\n",
    "   - Indicates that $ Y $ almost always occurs when $ X $ occurs.\n",
    "   - Example: If $ X = \\{\\text{bread}\\} $ and $ Y = \\{\\text{butter}\\} $, a high confidence implies that customers buying bread are very likely to buy butter.\n",
    "\n",
    "2. **Low Confidence ($ \\approx 0 $)**:\n",
    "   - Indicates that $ Y $ rarely occurs when $ X $ occurs.\n",
    "   - Example: If $ X = \\{\\text{bread}\\} $ and $ Y = \\{\\text{cereal}\\} $, a low confidence implies that buying bread is not strongly associated with buying cereal.\n",
    "\n",
    "**Thresholds in Practice**\n",
    "\n",
    "The minimum values for **confidence** depend on the specific dataset and the business context, but here are some common guidelines and starting points:\n",
    "- **Typical Threshold**: \n",
    "  - **70-80%**: Commonly used as a starting point for reliable rules.\n",
    "  - Adjust based on your use case:\n",
    "    - Lower threshold (50-60%) for exploratory insights.\n",
    "    - Higher threshold (90%+) for high-accuracy recommendations.\n",
    "- **Reason**: Rules with low confidence may not reliably predict the consequent item, making them less actionable.\n",
    "\n",
    "**Example**:  \n",
    "A rule with 30% confidence means that only 30% of the time, the consequent is bought when the antecedent is bought. This may not justify a marketing strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "............................................................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confidence vs. Other Metrics**\n",
    "- Having **High Confidence** results can lead to misleading rules if $ Y $ is very frequent in the dataset. For example, a high-confidence rule might occur simply because $ Y $ is common, not because $ X $ and $ Y $ are strongly related.\n",
    "- To address this, metrics like **lift** or **conviction** are often used alongside confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "............................................................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.3. Lift**: \n",
    "Lift measures the **ratio** or the strength of the association between two items or itemsets. Specifically, it compares the observed co-occurrence of items to their expected co-occurrence if they were independent.<br>\n",
    "In other words, lift shows whether the items are occurring together more often than expected by chance. Higher values are better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Lift(X → Y)} = \\frac{\\text{Confidence(X → Y)}}{\\text{Support(Y)}} $$\n",
    "\n",
    "$$\n",
    "\\text{Lift}(X \\rightarrow Y) = \\frac{\\text{Support}(X  ∩ Y)}{\\text{Support}(X) \\times \\text{Support}(Y)}\n",
    "$$\n",
    "\n",
    "**Valid Values for Lift**\n",
    "1. **Greater than 1**:  \n",
    "   - Indicates a **positive association** between $ X $ and $ Y $.\n",
    "   - $ X $ and $ Y $ are more likely to occur together than if they were independent.\n",
    "\n",
    "2. **Equal to 1**:  \n",
    "   - Indicates **no association** between $ X $ and $ Y $.\n",
    "   - $ X $ and $ Y $ occur together just as often as would be expected under independence.\n",
    "\n",
    "3. **Less than 1**:  \n",
    "   - Indicates a **negative association** between $ X $ and $ Y $.\n",
    "   - $ X $ and $ Y $ are less likely to occur together than if they were independent.\n",
    "\n",
    "**Thresholds in Practice**\n",
    "\n",
    "The minimum values for **lift** depend on the specific dataset and the business context, but here are some common guidelines and starting points:\n",
    "- **Typical Threshold**: \n",
    "  - **Lift > 1**: Indicates a positive association between items (start considering rules here).\n",
    "  - **Lift > 3**: Strong and actionable association.\n",
    "  - **Lift = 1**: No association (ignore these rules).\n",
    "  - **Lift < 1**: Negative association (discard unless relevant for avoiding recommendations).\n",
    "\n",
    "**Example**:  \n",
    "If Lift = 1.5, buying the antecedent increases the likelihood of buying the consequent by 50%. If Lift = 4, it’s a much stronger association."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Lift is Useful\n",
    "Lift helps overcome a major limitation of confidence alone. Consider this scenario: if bread appears in 80% of all transactions, then any rule \"X → bread\" will have high confidence simply because bread is popular, not because there's a meaningful association. Lift corrects for this by normalizing against the baseline probability of the consequent.\n",
    "\n",
    "Practical Example\n",
    "Let's say we're analyzing a grocery store dataset with 1,000 transactions:\n",
    "Data:\n",
    "\n",
    "Bread appears in 600 transactions (Support = 0.6)\n",
    "Butter appears in 400 transactions (Support = 0.4)\n",
    "Bread and Butter together appear in 300 transactions (Support = 0.3)\n",
    "\n",
    "For the rule \"Bread → Butter\":\n",
    "\n",
    "Confidence = 300/600 = 0.5 (50%)\n",
    "Lift = 0.5/0.4 = 1.25\n",
    "\n",
    "Interpretation: People who buy bread are 25% more likely to also buy butter than the average customer. This suggests a meaningful positive association.\n",
    "Comparison with a weak association:\n",
    "If we had a rule \"Bread → Milk\" where:\n",
    "\n",
    "Milk appears in 300 transactions (Support = 0.3)\n",
    "Bread and Milk together appear in 180 transactions\n",
    "\n",
    "Then:\n",
    "\n",
    "Confidence = 180/600 = 0.3 (30%)\n",
    "Lift = 0.3/0.3 = 1.0\n",
    "\n",
    "This lift of 1.0 indicates no special association between bread and milk beyond what we'd expect by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "............................................................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Starting Points for General Use:\n",
    "- **Support ≥ 5-10%**  \n",
    "- **Confidence ≥ 70-80%**  \n",
    "- **Lift > 1 (preferably > 3 for strong rules)**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "............................................................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule Prioritization\n",
    "To prioritize rules, combine the metrics:\n",
    "1. **High Lift + High Confidence + Acceptable Support**: These are the most actionable rules.\n",
    "   - Example: If $ \\text{Lift} = 4 $, $ \\text{Confidence} = 85\\% $, and $ \\text{Support} = 12\\% $, this rule is strong and impacts many customers.\n",
    "2. **Trade-offs**:\n",
    "   - Rules with **low support** but **high confidence and lift** might still be valuable for niche promotions.\n",
    "   - Rules with **high support** but **low lift** may indicate popular combinations that are obvious and less insightful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Step 6: Generate Association Rules**\n",
    "\n",
    "Now, use the frequent itemsets to generate association rules and calculate their metrics: **support**, **confidence**, and **lift**.\n",
    "\n",
    "Rules from `{Milk, Bread, Butter}`:\n",
    "1. **Rule**: $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$\n",
    "   - **Support**: $$ P(\\text{Milk, Bread, Butter}) = 6/12 = 50\\% $$\n",
    "   - **Confidence**: \n",
    "     $$\n",
    "     P(\\text{Butter}|\\text{Milk, Bread}) = \\frac{P(\\text{Milk, Bread, Butter})}{P(\\text{Milk, Bread})} = \\frac{6}{7} = 85\\%\n",
    "     $$\n",
    "   - **Lift**: \n",
    "     $$\n",
    "     \\text{Lift} = \\frac{P(\\text{Butter}|\\text{Milk, Bread})}{P(\\text{Butter})} = \\frac{0.85}{0.83} \\approx 1.02\n",
    "     $$\n",
    "\n",
    "2. **Rule**: $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$\n",
    "   - **Support**: $$ P(\\text{Milk, Bread, Butter}) = 6/12 = 50\\% $$\n",
    "   - **Confidence**:\n",
    "     $$\n",
    "     P(\\text{Bread}|\\text{Milk, Butter}) = \\frac{P(\\text{Milk, Bread, Butter})}{P(\\text{Milk, Butter})} = \\frac{6}{7} = 85\\%\n",
    "     $$\n",
    "   - **Lift**:\n",
    "     $$\n",
    "     \\text{Lift} = \\frac{P(\\text{Bread}|\\text{Milk, Butter})}{P(\\text{Bread})} = \\frac{0.85}{0.83} \\approx 1.02\n",
    "     $$\n",
    "\n",
    "3. **Rule**: $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$\n",
    "   - **Support**: $$ P(\\text{Milk, Bread, Butter}) = 6/12 = 50\\% $$\n",
    "   - **Confidence**:\n",
    "     $$\n",
    "     P(\\text{Milk}|\\text{Bread, Butter}) = \\frac{P(\\text{Milk, Bread, Butter})}{P(\\text{Bread, Butter})} = \\frac{6}{9} \\approx 66\\%\n",
    "     $$\n",
    "   - **Lift**:\n",
    "     $$\n",
    "     \\text{Lift} = \\frac{P(\\text{Milk}|\\text{Bread, Butter})}{P(\\text{Milk})} = \\frac{0.66}{0.75} \\approx .88\n",
    "     $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Final Results**\n",
    "\n",
    "Frequent Itemsets:\n",
    "- **1-itemsets**: `{Milk}`, `{Bread}`, `{Butter}`\n",
    "- **2-itemsets**: `{Milk, Bread}`, `{Milk, Butter}`, `{Bread, Butter}`\n",
    "- **3-itemset**: `{Milk, Bread, Butter}`\n",
    "\n",
    "Rules:\n",
    "| Rule                           | Support | Confidence | Lift  | Actionable? |\n",
    "|--------------------------------|---------|------------|-------|-------------|\n",
    "| $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$ | 50%     | 85%      | 1.02  | Yes         |\n",
    "| $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$ | 50%     | 85%      | 1.02  | Yes         |\n",
    "| $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$ | 50%     | 66%      | .88  | No         |\n",
    "\n",
    "**Interpretation and Actionable Insights**\n",
    "| Rule                           | Explaniation |\n",
    "|--------------------------------|--------------|\n",
    "| $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$ |Customers buying Milk and Bread are highly likely (85%) to also buy Butter. Consider bundling these items.         |\n",
    "| $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$ | Strong association; placing these items together could increase sales.         |\n",
    "| $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$ | Suggests that Milk is a complementary product to Bread and Butter, Weak lift thought         |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Python Code Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement the **Apriori algorithm** using the **`mlxtend`** library for frequent itemset mining and rule generation.\n",
    "\n",
    "**a. Install Required Libraries**\n",
    "Make sure you have the required libraries installed:\n",
    "```bash\n",
    "pip install pandas mlxtend\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Load the Dataset**\n",
    "We will represent the dataset as a **binary transaction matrix** where each row is a transaction, and each column is an item (1 = purchased, 0 = not purchased)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Dataset:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Milk",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Egg",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Bread",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Butter",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ketchup",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cookies",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a1124ba0-7eb8-46ed-b6f2-06fdf168e76a",
       "rows": [
        [
         "0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "1",
         "1",
         "1",
         "0",
         "1",
         "1",
         "0"
        ],
        [
         "2",
         "0",
         "0",
         "1",
         "1",
         "1",
         "0"
        ],
        [
         "3",
         "1",
         "0",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "4",
         "0",
         "0",
         "1",
         "1",
         "0",
         "1"
        ],
        [
         "5",
         "1",
         "0",
         "1",
         "1",
         "0",
         "1"
        ],
        [
         "6",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1"
        ],
        [
         "7",
         "1",
         "0",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "8",
         "0",
         "1",
         "1",
         "1",
         "0",
         "1"
        ],
        [
         "9",
         "1",
         "0",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "10",
         "1",
         "0",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "11",
         "1",
         "0",
         "1",
         "0",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Milk</th>\n",
       "      <th>Egg</th>\n",
       "      <th>Bread</th>\n",
       "      <th>Butter</th>\n",
       "      <th>Ketchup</th>\n",
       "      <th>Cookies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Milk  Egg  Bread  Butter  Ketchup  Cookies\n",
       "0      1    1      1       1        0        0\n",
       "1      1    1      0       1        1        0\n",
       "2      0    0      1       1        1        0\n",
       "3      1    0      1       1        0        0\n",
       "4      0    0      1       1        0        1\n",
       "5      1    0      1       1        0        1\n",
       "6      1    0      0       0        0        1\n",
       "7      1    0      1       1        0        0\n",
       "8      0    1      1       1        0        1\n",
       "9      1    0      1       1        0        0\n",
       "10     1    0      1       1        0        0\n",
       "11     1    0      1       0        1        1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the dataset\n",
    "data = {\n",
    "    \"Milk\":    [1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1],\n",
    "    \"Egg\":     [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    \"Bread\":   [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
    "    \"Butter\":  [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0],\n",
    "    \"Ketchup\": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "    \"Cookies\": [0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1],\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Transaction Dataset:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Apply the Apriori Algorithm**\n",
    "We will use the `mlxtend` library to find frequent itemsets and generate association rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (3.9.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /home/me/myenv/lib/python3.12/site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/me/myenv/lib/python3.12/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/me/myenv/lib/python3.12/site-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/me/myenv/lib/python3.12/site-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/me/myenv/lib/python3.12/site-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/me/myenv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.4\n"
     ]
    }
   ],
   "source": [
    "! pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets:\n",
      "    support               itemsets\n",
      "0  0.750000                 (Milk)\n",
      "1  0.833333                (Bread)\n",
      "2  0.833333               (Butter)\n",
      "3  0.583333          (Bread, Milk)\n",
      "4  0.583333         (Milk, Butter)\n",
      "5  0.750000        (Bread, Butter)\n",
      "6  0.500000  (Bread, Milk, Butter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me/myenv/lib/python3.12/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Step 1: Generate frequent itemsets with Apriori\n",
    "frequent_itemsets = apriori(df, min_support=0.5, use_colnames=True)\n",
    "\n",
    "# Display frequent itemsets\n",
    "print(\"\\nFrequent Itemsets:\")\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Generate Association Rules**\n",
    "We generate rules based on **confidence** and calculate **lift**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate rules based on confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules:\n",
      "      antecedents consequents   support  confidence      lift\n",
      "0         (Bread)      (Milk)  0.583333    0.700000  0.933333\n",
      "1          (Milk)     (Bread)  0.583333    0.777778  0.933333\n",
      "2        (Butter)      (Milk)  0.583333    0.700000  0.933333\n",
      "3          (Milk)    (Butter)  0.583333    0.777778  0.933333\n",
      "4        (Butter)     (Bread)  0.750000    0.900000  1.080000\n",
      "5         (Bread)    (Butter)  0.750000    0.900000  1.080000\n",
      "6   (Milk, Bread)    (Butter)  0.500000    0.857143  1.028571\n",
      "7  (Butter, Milk)     (Bread)  0.500000    0.857143  1.028571\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate association rules based on confidence\n",
    "rules = association_rules(frequent_itemsets, num_itemsets=len(df), metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Display the rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate rules based on lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules:\n",
      "      antecedents     consequents  support  confidence      lift\n",
      "0        (Butter)         (Bread)     0.75    0.900000  1.080000\n",
      "1         (Bread)        (Butter)     0.75    0.900000  1.080000\n",
      "2   (Milk, Bread)        (Butter)     0.50    0.857143  1.028571\n",
      "3  (Butter, Milk)         (Bread)     0.50    0.857143  1.028571\n",
      "4         (Bread)  (Butter, Milk)     0.50    0.600000  1.028571\n",
      "5        (Butter)   (Milk, Bread)     0.50    0.600000  1.028571\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate association rules based on lift\n",
    "rules = association_rules(frequent_itemsets, num_itemsets=len(df), metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Display the rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. Filter and Interpret Rules**\n",
    "You can filter rules for high lift or specific itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Rules with Lift > 1:\n",
      "      antecedents     consequents  support  confidence      lift\n",
      "0        (Butter)         (Bread)     0.75    0.900000  1.080000\n",
      "1         (Bread)        (Butter)     0.75    0.900000  1.080000\n",
      "2   (Milk, Bread)        (Butter)     0.50    0.857143  1.028571\n",
      "3  (Butter, Milk)         (Bread)     0.50    0.857143  1.028571\n",
      "4         (Bread)  (Butter, Milk)     0.50    0.600000  1.028571\n",
      "5        (Butter)   (Milk, Bread)     0.50    0.600000  1.028571\n"
     ]
    }
   ],
   "source": [
    "# Filter rules with Lift > 1\n",
    "filtered_rules = rules[rules['lift'] > 1]\n",
    "print(\"\\nFiltered Rules with Lift > 1:\")\n",
    "print(filtered_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " **Interpretation**\n",
    "1. $$ \\text{Milk, Bread} \\rightarrow \\text{Butter} $$ \n",
    "   - Support = 58%, Confidence = 87.5%, Lift = 1.05.\n",
    "   - Suggest bundling these items for promotions.\n",
    "2. $$ \\text{Milk, Butter} \\rightarrow \\text{Bread} $$\n",
    "   - Similar metrics as above, showing strong relationships.\n",
    "3. $$ \\text{Bread, Butter} \\rightarrow \\text{Milk} $$\n",
    "   - High confidence but slightly weaker lift, still actionable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Items Rules\n",
    "\n",
    "If desired, association rules at the 1-item values of X could be specified. \n",
    "Consider the rule: Milk → Bread.<br>\n",
    "Out of total 12 transactions Milk occurs 9 times while (Milk, Bread) occurs 7 times.<br>\n",
    "The rule has a support level of 7/12 (or 58 percent) and a confidence level of 7/9 (or 77 percent).<br>\n",
    "Thus, the next valid association rule is as follows:<br>\n",
    "Milk → Bread {S = 58%, C = 77%}.\n",
    "\n",
    "\n",
    " **2-Item Rules vs 3-Items Rules**\n",
    "**2-Item Rules**\n",
    "- **Simplicity**: Easier to interpret and implement in business decisions.\n",
    "- **Higher Support and Confidence**: More likely to appear frequently in transactions due to fewer constraints.\n",
    "- **Broad Applicability**: Useful for general trends, such as $ \\text{Milk} \\rightarrow \\text{Bread} $, which can inform store layout or promotions.\n",
    "\n",
    "**3-Item Rules**\n",
    "- **Deeper Insights**: Reveal more specific patterns, such as $ \\text{Milk, Bread} \\rightarrow \\text{Butter} $, which may not be evident in 2-item rules.\n",
    "- **Lower Support**: Less likely to occur because all three items must appear together.\n",
    "- **Targeted Application**: Better suited for niche marketing strategies or tailored product bundles.\n",
    "\n",
    "**Which is Better?**\n",
    "- **2-item rules** are ideal for identifying general trends and implementing broader strategies.\n",
    "- **3-item rules** are more appropriate for uncovering specific patterns and enabling targeted interventions.\n",
    "\n",
    "The choice between the two depends on the dataset's characteristics and the business objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association Rule Use Cases and Domains\n",
    "\n",
    "Association rule mining can be applied in various domains beyond market basket analysis. Here are some examples:\n",
    "\n",
    " 1. **Healthcare**\n",
    "   - **Disease Diagnosis:** Identifying associations between symptoms and diseases. For example, a rule like *{fever, cough} → {flu}* can help predict diseases.\n",
    "   - **Drug Interactions:** Discovering relationships between medications that are frequently prescribed together or identifying combinations that lead to adverse reactions.\n",
    "\n",
    " 2. **Web Usage Mining**\n",
    "   - **Website Optimization:** Analyzing user navigation patterns to determine common paths or clicks, e.g., *{homepage → product page} → {checkout}*.\n",
    "   - **Recommendation Systems:** Suggesting content or products based on frequently co-accessed items, e.g., *{clicked 'smartphone'} → {clicked 'smartphone accessories'}*.\n",
    "\n",
    " 3. **Education**\n",
    "   - **Student Behavior Analysis:** Discovering patterns in course enrollment, such as *{math101, cs101} → {stat101}*.\n",
    "   - **Learning Paths:** Identifying sequences of topics that students study, helping design better curricula.\n",
    "\n",
    " 4. **Telecommunications**\n",
    "   - **Customer Churn Analysis:** Detecting combinations of usage patterns that are associated with customers leaving the service, e.g., *{low data usage, few calls} → {churn}*.\n",
    "   - **Service Bundling:** Identifying services that are commonly purchased together, like *{broadband, mobile} → {TV subscription}*.\n",
    "\n",
    " 5. **Banking and Finance**\n",
    "   - **Fraud Detection:** Uncovering patterns associated with fraudulent transactions, e.g., *{high transaction frequency, odd hours} → {fraud}*.\n",
    "   - **Loan Approvals:** Identifying attributes of successful loan applications, such as *{high income, good credit score} → {loan approved}*.\n",
    "\n",
    " 6. **Manufacturing**\n",
    "   - **Fault Detection:** Identifying combinations of machine conditions that frequently result in faults, e.g., *{high temperature, low pressure} → {equipment failure}*.\n",
    "   - **Supply Chain Optimization:** Discovering patterns in material usage, e.g., *{material A, material B} → {product C}*.\n",
    "\n",
    " 7. **Retail Beyond Market Basket**\n",
    "   - **Shelf Placement:** Finding products that are often bought together to optimize store layout.\n",
    "   - **Customer Segmentation:** Identifying customer groups with similar purchasing behaviors, e.g., *{frequent discount purchases} → {low brand loyalty}*.\n",
    "\n",
    " 8. **Social Media Analysis**\n",
    "   - **Trending Topics:** Discovering associations between hashtags, e.g., *{#climatechange, #sustainability} → {#renewableenergy}*.\n",
    "   - **User Behavior Patterns:** Understanding engagement behaviors, such as *{likes post, comments on post} → {shares post}*.\n",
    "\n",
    " 9. **Energy Sector**\n",
    "   - **Usage Patterns:** Identifying associations in energy usage, like *{high A/C usage, weekend} → {peak energy consumption}*.\n",
    "   - **Smart Grid Analysis:** Detecting patterns for predictive maintenance, e.g., *{low voltage, high demand} → {power outage}*.\n",
    "\n",
    " 10. **Transportation and Logistics**\n",
    "   - **Traffic Analysis:** Discovering patterns in traffic conditions, e.g., *{morning rush hour, bad weather} → {traffic jam}*.\n",
    "   - **Route Optimization:** Identifying frequently used delivery routes, such as *{route A, route B} → {delivered faster}*. \n",
    "\n",
    " 11. **E-commerce**\n",
    "   - **User Preferences:** Identifying patterns in user preferences for personalized recommendations.\n",
    "   - **Cross-Selling:** Suggesting related products based on purchase history.\n",
    "\n",
    " 12. **Sports Analytics**\n",
    "   - **Performance Metrics:** Discovering combinations of player actions that lead to victories, e.g., *{high possession, accurate passes} → {win}*.\n",
    "   - **Injury Prevention:** Identifying conditions that precede injuries, such as *{high training load, lack of rest} → {injury risk}*. \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
